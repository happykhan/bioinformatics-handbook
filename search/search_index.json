{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to The Microbial Bioinformatics Handbook","text":"<p>How to speak bioinformatician?</p>"},{"location":"#license","title":"License","text":"<p>Unless otherwise stated, content presented here is under a CC BY-SA 4.0 licence, which basically means you are free to:</p> <ul> <li>Share \u2014 copy and redistribute the material in any medium or format for any purpose, even commercially.</li> <li>Adapt \u2014 remix, transform, and build upon the material for any purpose, even commercially.</li> </ul> <p>Given:</p> <ul> <li>Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.</li> <li>ShareAlike \u2014 If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.</li> </ul>"},{"location":"#support","title":"Support","text":"<p>I am hoping to expand on the content here in my spare time. If you like the content here and want to see more, please support me via liberapay: https://liberapay.com/happykhan</p>"},{"location":"glossary/","title":"Glossary","text":""},{"location":"glossary/#base-quality","title":"Base Quality","text":"<p>The quality score associated with each base in a sequencing read, indicating the probability that the base is called correctly. It is often represented using Phred scores. Utilized to filter and trim sequencing reads to improve overall data quality and reliability. Typically visualized in quality control tools to identify regions of low-quality bases within sequencing reads.</p>"},{"location":"glossary/#de-novo-genome-assembly","title":"De novo genome assembly","text":"<p>The process of reconstructing a complete genome sequence from DNA sequencing reads without the aid of a reference genome. De novo assembly is typically performed when a reference genome is not available or when studying non-model organisms with significant genetic variation (i.e. most bacteria). De novo assembly poses several challenges, including repetitive regions, sequencing errors, and variations in genome structure and complexity. During de novo assembly, sequenced reads are overlapped and assembled into contiguous stretches of DNA, known as contigs. Additional steps may be performed to order and orient contigs into larger scaffolds, using paired-end or mate-pair information to bridge gaps between contigs and improve the continuity and accuracy of the assembly.</p>"},{"location":"glossary/#fastq","title":"FASTQ","text":"<p>A text-based format for storing both nucleotide sequence data and corresponding quality scores. Each entry in a FASTQ file consists of four lines: a sequence identifier, the raw sequence, a plus sign, and a string of quality scores. Widely used for storing and sharing raw sequencing data from high-throughput sequencing platforms. For example, </p> <pre><code>@SEQ_ID\nGATTTGGGGTTCAAAGCAGTATCGATCAAATAGTAAATTTGTGTTAAATACAAAATT\n+\n!''*((((***+))%%%++)(%%%%).1***-+*''))**55CCF&gt;&gt;&gt;&gt;&gt;&gt;CCCCCCC65\n</code></pre>"},{"location":"glossary/#phred-score","title":"Phred Score","text":"<p>A measure of the quality of the identification of nucleotides generated by sequencing machines, represented on a logarithmic scale. The score ( Q ) is calculated as ( Q = -10 log_10 P ), where ( P ) is the probability of an incorrect base call. Used to assess the accuracy of individual base calls in sequencing data. Higher Phred scores indicate higher confidence. For example, a Phred score of 20 corresponds to a 1% error rate (i.e. 99% accuracy).</p>"},{"location":"glossary/#sequenced-reads","title":"Sequenced Reads","text":"<p>Short fragments of DNA or RNA sequences that are output from sequencing machines. Each read represents a portion of the original DNA or RNA molecule being sequenced. Sequenced reads are the raw data used for downstream bioinformatics analyses, such as alignment to a reference genome, variant calling, and assembly. Reads can be single-end (one end of the fragment is sequenced) or paired-end (both ends of the fragment are sequenced, providing more information for alignment and assembly).</p>"},{"location":"assembly-compare/assembly-hybrid-short-read/","title":"Hybrid and short-read-only assembly of sequenced reads","text":"<p>In this exercise, you will take the reads of our novel pathogen and assembly the genome using the short reads alone and a hybrid assembly using both long and short reads. This is to illustrate how differences in sequencing data (namely, read length) will affect the final outcome. We will use these assemblies in subsequent analyses.  </p> <p>If you are unsure about files and file types, please review Crash Course Computer Science episode 20. The Crash Course Computer Science episode 21 is also helpful in understanding compression (.gz, .zip). The episode on operating systems will also help you understand <code>Unix</code> a little better. </p>"},{"location":"assembly-compare/assembly-hybrid-short-read/#short-read-assembly-with-shovill","title":"Short read assembly with Shovill","text":"<p>About Shovill: The SPAdes genome assembler has become the de facto standard de novo genome assembler for Illumina whole genome sequencing data of bacteria and other small microbes. </p> <p>SPAdes was a major improvement over previous assemblers like Velvet, but some of its components can be slow and it traditionally did not handle overlapping paired-end reads well. </p> <p>Shovill is a pipeline which uses SPAdes at its core, but alters the steps before and after the primary assembly step to get similar results in less time. Shovill also supports other assemblers like SKESA, Velvet and Megahit, so you can take advantage of the pre- and post-processing the Shovill provides with those too. </p> <p>Warning: Shovill is for isolate data only, primarily small haploid organisms. It will NOT work on metagenomes or larger genomes. Please use Megahit directly instead. See more details at https://github.com/tseemann/shovill</p>"},{"location":"assembly-compare/assembly-hybrid-short-read/#doing-short-read-assembly-with-shovill","title":"Doing short read assembly with Shovill","text":"<p>Is Shovill installed? Please see the Installing software section.</p> <p>We can run Shovill with: <pre><code>shovill  --R1 novel-pathogen_R1.fastq.gz  \\\n         --R2 novel-pathogen_R2.fastq.gz   \\\n         --outdir short_read_only --force\n</code></pre></p> <p>The final output: </p> <pre><code>[shovill] Repaired 0 contigs from spades.fasta at 0 positions.\n[shovill] Assembly is 4938311, estimated genome size was 4712883 (+4.78%)\n[shovill] Using genome graph file 'spades/assembly_graph_with_scaffolds.gfa' =&gt; 'contigs.gfa'\n[shovill] Walltime used: 3 min 6 sec\n[shovill] Results in: /home/ubuntu/code/mmbdtp.github.io/temp/short_read_only\n[shovill] Final assembly graph: /home/ubuntu/code/mmbdtp.github.io/temp/short_read_only/contigs.gfa\n[shovill] Final assembly contigs: /home/ubuntu/code/mmbdtp.github.io/temp/short_read_only/contigs.fa\n[shovill] It contains 297 (min=75) contigs totalling 4938311 bp.\n[shovill] More correct contigs is better than fewer wrong contigs.\n[shovill] Done.\n</code></pre> <p>The contents of the <code>short_read_only</code> folder: </p> <pre><code>(shovill) ubuntu@chomp:~/code/mmbdtp.github.io/temp$ ls short_read_only/ -hl\ntotal 15M\n-rw-rw-r-- 1 ubuntu ubuntu 4.9M Nov  2 17:01 contigs.fa\n-rw-rw-r-- 1 ubuntu ubuntu 4.8M Nov  2 17:01 contigs.gfa\n-rw-rw-r-- 1 ubuntu ubuntu    0 Nov  2 17:01 shovill.corrections\n-rw-rw-r-- 1 ubuntu ubuntu 365K Nov  2 17:01 shovill.log\n-rw-rw-r-- 1 ubuntu ubuntu 4.8M Nov  2 17:01 spades.fasta\n</code></pre> <p>The important output files, please review each of these:</p> <ul> <li>contigs.fa: The final assembly you should use</li> <li>contigs.gfa: Assembly graph (spades)</li> <li>shovill.log: Full log file for bug reporting</li> </ul>"},{"location":"assembly-compare/assembly-hybrid-short-read/#hybrid-assembly-with-unicyler","title":"Hybrid assembly with Unicyler","text":"<p>There are different programs for hybrid assembly, with slightly different results. So, why Unicycler?</p> <ul> <li>All in one package - Good hybrid assembly</li> <li>Can use short read only and bridge gaps with some guesswork </li> <li>A lot of options on how aggressive you want it to join contigs</li> <li>Easy install</li> <li>Checks for circularisation </li> </ul>"},{"location":"assembly-compare/assembly-hybrid-short-read/#doing-hybrid-assembly-with-unicyler","title":"Doing hybrid assembly with Unicyler","text":"<p>Is Unicyler installed? Please see the Installing software section. </p> <p>We can run Unicyler with: <pre><code>unicycler -1 novel-pathogen_R1.fastq.gz \\\n  -2 novel-pathogen_R2.fastq.gz \\\n  -l novel-pathogen-long-reads.fastq.gz  \\\n  -o hybrid_assembly\n</code></pre></p> <p>The contents of the <code>hybrid_assembly</code> folder: </p> <pre><code>001_spades_graph_k027.gfa\n001_spades_graph_k053.gfa\n001_spades_graph_k071.gfa\n001_spades_graph_k087.gfa\n001_spades_graph_k099.gfa\n001_spades_graph_k111.gfa\n001_spades_graph_k119.gfa\n001_spades_graph_k127.gfa\n002_depth_filter.gfa\n003_overlaps_removed.gfa\n004_long_read_assembly.gfa\n005_bridges_applied.gfa\n006_final_clean.gfa\nassembly.fasta\nassembly.gfa\nunicycler.log\n</code></pre> <p>At this stage, you may want to ask about what's different about a hybrid assembly?</p> <p>The important output files:</p> <ul> <li>assembly.fasta: The final assembly you should use</li> <li>assembly.gfa: Assembly graph </li> <li>unicycler.log: Full log file for bug reporting</li> </ul>"},{"location":"assembly-compare/assembly-hybrid-short-read/#exercise-1-short-read-and-hybrid-assembly","title":"Exercise 1: Short read and hybrid assembly","text":""},{"location":"assembly-compare/assembly-hybrid-short-read/#theory-questions","title":"Theory questions","text":"<p>Define \"Read 1\" and \"Read 2\" in the context of paired-end sequencing. What is the direction of extension for each?</p> <p>Explain the term \"homopolymers\" and why they are difficult to read accurately in sequencing.</p> <p>Why is it important for read lengths to span repeated sequences in the genome during assembly?</p> <p>What issues do some sequencing platforms encounter when dealing with GC-rich or AT-rich DNA sequences?</p>"},{"location":"assembly-compare/assembly-hybrid-short-read/#practical-questions","title":"Practical questions","text":"<p>Assemble the genome of our novel pathogen using short reads only </p> <p>Assemble the genome of our novel pathogen using both long and short reads (as a hybrid assembly)</p> <p>We will compare the results of these assemblies in the next exercise</p> <p>Answers to the exercises</p> <p>Back to Programme.</p>"},{"location":"concepts/fastq-in-detail/","title":"FASTQ in detail","text":"<p>FASTQ is a common file format used in bioinformatics and genomics to represent raw DNA sequencing data. It contains information about the sequences of DNA or RNA fragments obtained from a high-throughput sequencing experiment, along with quality scores for each base in the sequence. FASTQ files can be generated by various sequencing platforms and are used in a wide range of bioinformatics applications, including genome assembly, variant calling, and transcriptomics analysis.</p> <p>Although it looks complicated (and maybe it is), the FASTQ format is easy to understand with a little decoding. A typical FASTQ file consists of four lines for each sequence entry:</p> <ol> <li>Header/Identifier line (starts with '@'): This line contains information about the sequence, often including a unique identifier, sequencing machine information, and other metadata.</li> <li>Sequence line: This line contains the actual sequence of DNA or RNA bases represented by letters (A for Adenine, T for Thymine, C for Cytosine, G for Guanine, and N for ambiguous bases).</li> <li>Quality score header line (starts with '+'): This line is usually just a placeholder and is often identical across all sequences in the file.</li> <li>Quality scores line: Has a string of characters which represent the quality scores associated with each base of the nucleic sequence; must have the same number of characters as line 2</li> </ol> <p>Here is an example of a FASTQ entry:</p> <pre><code>@M00970:337:000000000-BR5KF:1:1102:17745:1557 1:N:0:CGCAGAAC+ACAGAGTT\nGTGCCAGCCGCCGCGGTAGTCCGACGTGGCTGTCTCTTATACACATCTCCGAGCCCACGAGACCGAAGAACATCTCGTATGCCGTCTTCTGCTTGAAAAAAAAAAAAAAAAAAAACAAAAAAAAAAAAAGAAGCAAATGACGATTCAAGAAAGAAAAAAACACAGAATACTAACAATAAGTCATAAACATCATCAACATAAAAAAGGAAATACACTTACAACACATATCAATATCTAAAATAAATGATCAGCACACAACATGACGATTACCACACATGTGTACTACAAGTCAACTA\n+\nGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGFGGGFGGGGGGAFFGGFGGGGGGGGFGGGGGGGGGGGGGGFGGG+38+35*311*6,,31=******441+++0+0++0+*1*2++2++0*+*2*02*/***1*+++0+0++38++00++++++++++0+0+2++*+*+*+*+*****+0**+0**+***+)*.***1**//*)***)/)*)))*)))*),)0(((-((((-.(4(,,))).,(())))))).)))))))-))-(\n</code></pre> <p>In this example: - <code>@M00970</code> is the header/identifier line. - The second line represents the DNA sequence. - The <code>+</code> is the quality score header. Sometimes you will see the header <code>+</code> followed by the same identifier as the header/identifier line. - The fourth line contains the quality scores.</p> <p>It means that the fragment named <code>@M00970</code> corresponds to the DNA sequence  <pre><code>GTGCCAGCCGCCGCGGTAGTCCGACGTGGCTGTCTCTTATACACATCTCCGAGCCCACGAGACCGAAGAACATCTCGTATGCCGTCTTCTGCTTGAAAAAAAAAAAAAAAAAAAACAAAAAAAAAAAAAGAAGCAAATGACGATTCAAGAAAGAAAAAAACACAGAATACTAACAATAAGTCATAAACATCATCAACATAAAAAAGGAAATACACTTACAACACATATCAATATCTAAAATAAATGATCAGCACACAACATGACGATTACCACACATGTGTACTACAAGTCAACTA \n</code></pre> and this sequence has been sequenced with a quality  <pre><code>GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGFGGGFGGGGGGAFFGGFGGGGGGGGFGGGGGGGGGGGGGGFGGG+38+35*311*6,,31=******441+++0+0++0+*1*2++2++0*+*2*02*/***1*+++0+0++38++00++++++++++0+0+2++*+*+*+*+*****+0**+0**+***+)*.***1**//*)***)/)*)))*)))*),)0(((-((((-.(4(,,))).,(())))))).)))))))-))-(.\n</code></pre></p> <p>We will see later how to interpret these quality scores, i.e. is <code>G</code> for good? or <code>)</code> better? but for now, just know that the higher the \"score\", the higher the probability that the base call is correct. </p> <p>Let's quickly discuss the header line. The header line (<code>@</code>) tells you a lot about the circumstances of where the read came from. Remember, in most sequencing technlogies we our sequenced reads are measurements taken across a flow cell. This a picture of an Illumina NextSeq flow cell: </p> <p></p> <p>This is the an example header line that we could see in a FASTQ file:</p> <pre><code>@HWI-ST863:195:D1P7AACXX:1:1101:1173:1855/1:N:0:CGCAGAAC+ACAGAGTT\n</code></pre> <ul> <li><code>@</code>: This is a FASTQ Header line</li> <li><code>HWI-ST863</code>: This is the instrument name</li> <li><code>195</code>: This is the run ID</li> <li><code>D1P7AACXX</code>: This is the flowcell ID</li> <li><code>1</code>: This is the flowcell lane</li> <li><code>1101</code>: This is the tile number</li> <li><code>1173</code>: This is the x-coordinate of the cluster</li> <li><code>1855</code>: This is the y-coordinate of the cluster</li> <li><code>/1</code>: This is the member of a pair, /1 or /2</li> <li><code>N</code>: This is the filter flag. Y if the read is filtered. N otherwise.</li> <li><code>0</code>: This is the number of control bits</li> <li><code>CGCAGAAC</code>, <code>ACAGAGTT</code>: These are the index sequences (also known as barcode sequences)</li> </ul> <p>This relates back to what we saw earlier this week. Say, for Illumina, sequencing machines contain one or more flow cells and each of these flow cells contains one or more lanes. Further, each lane has hundreds of quadrants, called tiles, containing oligos that bind your library.  Illumina machines employ sequencing by synthesis technology. First, individual reads are amplified in tight clonal clusters, which is done to increase signal. This amplification uses the terminal elements of the adapter in a process referred to as bridge amplification. After amplification, a PCR-like reaction is used to incorporate fluorescent nucleotides one at a time.</p> <p></p> <p>For each sequencing cycle completed, an image like the one above is produced. Each colored dot corresponds to a clonal cluster derived from one DNA fragment. Illumina's processing algorithm takes images like the one above and translates it into a base call for each read at each position, along with a corresponding measure of certainty in the base call.</p> <p>Many issues can arise during the sequencing by synthesis process. A common issue is the tendency for some fragments in a clonal cluster to not incorporate a nucleotide toward the end of the process, when sequencing reagents become more limiting. This leads to ambiguity in base calls near the 3' end of reads.</p>"},{"location":"concepts/fastq-in-detail/#representing-errors-or-uncertainty-in-sequencing-data","title":"Representing errors or uncertainty in sequencing data","text":"<p>Modern sequencing technologies can generate a massive number of sequence reads in a single experiment. However, no sequencing technology is perfect, and each instrument will generate different types and amount of errors, such as incorrect nucleotides being called. These wrongly called bases are due to the technical limitations of each sequencing platform.</p> <p>Therefore, it is necessary to understand, identify and exclude error-types that may impact the interpretation of downstream analysis. Sequence quality control is therefore an essential first step in your analysis. Catching errors early saves time later on.</p> <p>But what does this quality score mean?</p> <p>The quality score for each sequence is a string of characters, one for each base of the nucleotide sequence, used to characterize the probability of misidentification of each base. The score is encoded using the ASCII character table (with some historical differences): </p> <p></p> <p>To save space, the sequencer records an ASCII character to represent scores 0-42. For example 10 corresponds to \u201c+\u201d and 40 corresponds to \u201cI\u201d. This is often called \u201cPhred\u201d scoring.</p> <p>So there is an ASCII character associated with each nucleotide, representing its Phred quality score, the probability of an incorrect base call:</p> Phred Quality Score Probability of incorrect base call Base call accuracy 10 1 in 10 90% 20 1 in 100 99% 30 1 in 1000 99.9% 40 1 in 10,000 99.99% 50 1 in 100,000 99.999% 60 1 in 1,000,000 99.9999% <p>What does 0-42 represent? These numbers, when plugged into a formula, tell us the probability of an error for that base. This is the formula, where Q is our quality score (0-42) and P is the probability of an error: <pre><code>Q = -10 log10(P)\n</code></pre></p> <p>Using this formula, we can calculate that a quality score of 40 means only 0.00010 probability of an error.</p>"},{"location":"concepts/fastq-in-detail/#exercise-review-questions","title":"Exercise: Review questions","text":"<p>For the FASTQ header line below, what is the run ID, the indexes used and name of the instrument?</p> <pre><code>@M00970:337:000000000-BR5KF:1:1102:17745:1557 1:N:0:CGCAGAAC+ACAGAGTT\n</code></pre> <p>Which ASCII character corresponds to the worst Phred score for Illumina 1.8+?</p> <p>What is the Phred quality score of the 3rd nucleotide of the following sequence?</p> <pre><code>@M00970: .... \nGTGCCAGCCGCCGCGGTAGTCCGACGTGGC\n+ \nGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG\n</code></pre> <p>What is the accuracy of this 3rd nucleotide?</p> <p>Answers for this exercise</p>"},{"location":"concepts/file-formats/","title":"Exploring file formats","text":"<p>While we talk about file \"formats\" for sequencing data these are not the same as file formats for propperity programs such as MS Word or binary file formats. These are simply text files with a particular structure. This means that you can open these files and read them as plain text even if the file extension is <code>.fastq</code>, <code>.fasta</code> and so on. </p>"},{"location":"concepts/file-formats/#common-file-formats","title":"Common file formats","text":"<p>Here are some common genomics sequence file formats, some of which we have mentioned already;. </p> Format Description FASTA A text-based format for representing nucleotide or protein sequences. Each sequence is represented by a header line starting with '&gt;', followed by the sequence data. FASTQ A format for representing both nucleotide sequences and their corresponding quality scores. Each record contains a sequence and quality scores in a readable text format. SAM (Sequence Alignment/Map) A tab-delimited text format for storing sequence alignment data, often used for mapping short reads to a reference genome. BAM (Binary Alignment/Map) A binary version of the SAM format, which is more compact and efficient for large datasets. Used for storing sequence alignment data. VCF (Variant Call Format) A text-based format for representing genetic variations, including single nucleotide polymorphisms (SNPs), insertions, deletions, and structural variants. BCF (Binary Call Format) A binary version of the VCF format, which is more compact and efficient for large datasets. BED (Browser Extensible Data) A text-based format for representing genomic intervals, such as regions of interest, gene annotations, and functional elements. GFF/GTF (General Feature Format/General Transfer Format) Text-based formats for representing genomic features, including genes, exons, and other structural elements. GFF is often used in older annotations, while GTF is commonly used in more recent annotations. FAST5 A format used by Oxford Nanopore Technologies (ONT) for storing raw sequencing data produced by their nanopore sequencing platforms."},{"location":"concepts/file-formats/#exercise-exploring-file-formats","title":"Exercise: Exploring file formats","text":"<p>The post-doc is on holiday, and you have been given a directory of mysterious sequence data files. You need to figure out what file format each file is in.</p> <pre><code>user:~/file-formats$ ls -lag \ntotal 68837\ndrwxr-xr-x 2 users       10 Oct 18 13:47 .\ndrwxr-xr-x 3 users        1 Oct 18 13:29 ..\n-rw-r--r-- 1 users   141566 Oct 18 13:32 pKP1-NDM-1.aries\n-rw-r--r-- 1 users 24137926 Oct 18 13:32 pKP1-NDM-1.cancer\n-rw-r--r-- 1 users  4170743 Oct 18 13:32 pKP1-NDM-1.gemini\n-rw-r--r-- 1 users  2598233 Oct 18 13:32 pKP1-NDM-1.leo\n-rw-r--r-- 1 users  4239662 Oct 18 13:32 pKP1-NDM-1.libra\n-rw-r--r-- 1 users 24539958 Oct 18 13:32 pKP1-NDM-1.pisces\n-rw-r--r-- 1 users  1316209 Oct 18 13:32 pKP1-NDM-1_R1.capricorn\n-rw-r--r-- 1 users  2728498 Oct 18 13:32 pKP1-NDM-1.scorpio\n-rw-r--r-- 1 users  3966215 Oct 18 13:42 pKP1-NDM-1.taurus\n-rw-r--r-- 1 users  2647629 Oct 18 13:32 pKP1-NDM-1.virgo\n</code></pre> <p>You can download a tarball of all the files from Zenodo. In general, example files should be in https://zenodo.org/records/10018484.</p> <p>For each of the files in the tarball, can you:</p> <ul> <li>Copy these files to your home directory. </li> <li>Identify the file format?</li> <li>List the common file extensions people use for the file formats you find?</li> <li>Can you define some general rules to differeniate the file format?</li> </ul> <p>Hint: Use common linux commands, such as <code>head</code>, <code>tail</code>, <code>less</code>, <code>cat</code>, <code>zcat</code> and so on. In case something gets stuck use CTRL-C or CTRL-Z. Ctrl+C is used to forcefully terminate a process, while Ctrl+Z is used to suspend a process and move it to the background, where it can be resumed or managed later. Remember that you can use pipes into <code>less</code> or <code>more</code> to make it easier to read the output of commands.</p> <p>What is this data? This is simulated reads of a plasmid that carries blaNDM genes, descibed here https://doi.org/10.1128/aac.00368-16. blaNDM genes confer carbapenem resistance and have been identified on transferable plasmids belonging to different incompatibility (Inc) groups. I chose a plasmid because it would create small files and would be easy to work with.</p> <p>Answers for this exercise.</p>"},{"location":"concepts/genome-assembly/","title":"What is a genome assembler doing?","text":"<p>Genome assemblers assume the following about sequenced reads:</p> <ul> <li>Reads are resolved into nucleotide bases (ATGC &amp; ambiguous base calls)</li> <li>Reads are randomly distributed across the target DNA, and</li> <li>Reads are represent an oversampling of the target DNA, such that individual reads repeatedly overlap</li> <li>Genome assemblers calculate overlaps between reads and (usually) represent as a graph/network. Then \u201cwalk\u201d the graph to determine the original sequence.</li> </ul> <p>Genome assemblers calculate overlaps between reads and (usually) represent as a graph/network. Then \u201cwalk\u201d the graph to determine the original sequence.</p> <p>See Torsten Seemann\u2019s slides on de novo genome assembly</p> <p></p> <p>Whole genome shotgun sequencing: Genome is sheared into small approximately equal sized fragments which are subsequently small enough to be sequenced in both directions followed by cloning. The cloned sequences (reads) are then fed to an assembler (illustrated in Figure 2). b To overcome some of the complexity of normal shotgun sequencing of large sequences such as genomes a hierarchical approach can be taken. The genome is broken into a series of large equal segments of known order which are then subject to shotgun sequencing. The assembly process here is simpler and less computationally expensive. From Commins, Toft and Fares 2009</p>"},{"location":"concepts/genome-assembly/#what-is-r1-and-r2","title":"What is R1 and R2?","text":"<p>Just as a reminder, many sequencing library preparation kits include an option to generate so-called \u201cpaired-end reads\u201c.  Intact genomic DNA is sheared into several million short DNA fragment.  Individual reads can be paired together to create paired-end reads, which offers some benefits for downstream bioinformatics data analysis algorithms.  The structure of a paired-end read is shown here.</p> <p></p> <p>\u201cRead 1\u201d, often called the \u201cforward read\u201d, extends from the \u201cRead 1 Adapter\u201d in the 5\u2032 \u2013 3\u2032 direction towards \u201cRead 2\u201d along the forward DNA strand.</p> <p>\u201cRead 2\u201d, often called the \u201creverse read\u201d, extends from the \u201cRead 2 Adapter\u201d in the 5\u2032 \u2013 3\u2032 direction towards \u201cRead 1\u201d along the reverse DNA strand.</p>"},{"location":"concepts/genome-assembly/#how-genome-assemblers-fail-perfection","title":"How genome assemblers fail perfection","text":"<p>In theory, Genome assembly software with perfect reads of good length will  reconstruct the genome verbatim </p> <p>However, Sequencing platform have errors (and cause errors downstream): </p> <ul> <li>Struggle with GC rich and/or AT rich DNA.</li> <li>Have lower read quality towards the end of reads (5', 3' or both ends)</li> <li>Have difficulty reading homopolymers (e.g. AAAAA or TTTTTTT) accurately</li> <li>Have read lengths that does not span repeated sequences in the genome</li> </ul> <p></p> <ul> <li>Repeats: A segment of DNA that occurs more than once in the genome</li> <li>Read length must span the repeat</li> </ul>"},{"location":"concepts/genome-assembly/#outcomes-of-your-final-contigs","title":"Outcomes of your final contigs","text":"<p>Mate-pair signatures for collapse style mis-assemblies. (a) Two copy tandem repeat R shown with properly sized and oriented mate-pairs. (b) Collapsed tandem repeat shown with compressed and mis-oriented mate-pairs. (c) Two copy repeat R, bounding unique sequence B, shown with properly sized and oriented mate-pairs. (d) Collapsed repeat shown with compressed and mis-linked mate-pairs. From https://doi.org/10.1186%2Fgb-2008-9-3-r55</p>"},{"location":"concepts/genome-assembly/#how-to-span-repeats","title":"How to span repeats:","text":"<ul> <li>Long reads (ONT, Pacbio)</li> <li>Long reads (Sanger)</li> <li>Optical mapping</li> <li>Hi-C</li> <li>Or just don\u2019t! </li> </ul>"},{"location":"concepts/sequence-alignment/","title":"Local vs global alignment","text":"<p>The Smith-Waterman and Needleman-Wunsch algorithms are both used for sequence alignment in bioinformatics, specifically for comparing and aligning sequences of amino acids or nucleotides (e.g., protein or DNA sequences). While they serve a similar purpose, there are key differences between the two algorithms.</p> <p>Smith-Waterman: This algorithm is used for local sequence alignment. It aims to find the best alignment of subsequences within the input sequences. It is ideal for identifying regions of similarity or homology between sequences, allowing for gaps and mismatches within the alignment.</p> <p>Needleman-Wunsch: This algorithm is used for global sequence alignment. It finds the best alignment of the entire input sequences, extending from the beginning to the end. Needleman-Wunsch is used when you want to compare entire sequences and ensure that all positions are considered, even if it means introducing gaps.</p>"},{"location":"concepts/sequence-alignment/#scoring-and-penalties","title":"Scoring and Penalties","text":"<p>Smith-Waterman: In local alignment, Smith-Waterman uses a scoring system that assigns positive scores for matches and negative scores for mismatches and gap penalties. This allows for flexible alignments that might include gaps and mismatches while maximizing the similarity of aligned regions.</p> <p>Needleman-Wunsch: In global alignment, Needleman-Wunsch also uses a scoring system for matches and mismatches but typically employs a gap penalty that discourages the introduction of gaps. This results in a global alignment that attempts to minimize gaps across the entire sequences.</p>"},{"location":"concepts/sequence-alignment/#purpose","title":"Purpose","text":"<p>Smith-Waterman: This algorithm is often used when you want to identify local regions of similarity or find local homologies within sequences. For example, it is useful for identifying conserved domains or functional motifs in proteins.</p> <p>Needleman-Wunsch: This algorithm is employed when you want to perform a global comparison of entire sequences. It is useful for determining the overall similarity between sequences and finding evolutionary relationships.</p>"},{"location":"concepts/sequence-alignment/#what-is-blosum","title":"What is BLOSUM","text":"<p>BLOSUM stands for \"BLOcks SUbstitution Matrix,\" and it is a term commonly used in the field of bioinformatics and computational biology. BLOSUM matrices are used in sequence alignment, a fundamental task in bioinformatics, to assess the similarity between two sequences of amino acids or nucleotides, typically for protein or DNA sequence comparisons.</p> <p>The BLOSUM matrices are used to calculate a score for aligning two sequences based on the observed frequencies of substitutions between different amino acids or nucleotides within a set of related sequences, often referred to as a \"block\" or a \"family\" of sequences. These matrices help determine the likelihood of specific substitutions occurring between amino acids or nucleotides within related sequences.</p>"},{"location":"concepts/sequence-data/","title":"Revisting sequence file formats","text":""},{"location":"concepts/sequence-data/#revisting-sequence-file-formats","title":"Revisting sequence file formats","text":"<p>In this session, we will revisit the different file formats used to store sequencing data. We will also discuss the different ways of representing errors or uncertainty in sequencing data.</p>"},{"location":"concepts/sequence-data/#representing-nucleotides","title":"Representing nucleotides","text":"<p>During sequencing, the nucleotide bases in a DNA or RNA sample (library) are determined by the sequencer. For each fragment in the library, a sequence is generated, also called a read, which is simply a succession of nucleotides. The sequence of a read is represented by a string of letters, where each letter represents a nucleotide base. The most common nucleotide bases are adenine (A), cytosine (C), guanine (G), and thymine (T). In RNA, thymine is replaced by uracil (U). </p> <p>Sequencing instruments may also give ambiguous signals, which are represented by the letters R, Y, S, W, K, M, B, D, H, V, and N. This convention was set by the International Union of Pure and Applied Chemistry (IUPAC) in 1985. These letters represent the following combinations of nucleotides:</p> IUPAC nucleotide code Base A Adenine C Cytosine G Guanine T (or U) Thymine (or Uracil) R A or G Y C or T S G or C W A or T K G or T M A or C B C or G or T D A or G or T H A or C or T V A or C or G N any base . or - gap <p>N means the base could not be determined. This is different from a gap, which means the base is not present in the sequence.</p> <p>Read Johnson 2010 for more details. </p>"},{"location":"concepts/sequence-data/#exercise-1-nucleotides","title":"Exercise 1: Nucleotides","text":"<p>Convert the following sequences to all possible combinations</p> <pre><code>ATGRCTAYCGTG\n</code></pre> <pre><code>ATGNATC-GTG\n</code></pre> <p>Write psuedocode or a program to check if a sequence is valid according the the IUPAC nucleotide code.</p> <p>This is difficult. </p> <p>Answers to exercises</p> <p>Next step: File formats</p> <p>Back to Programme.</p>"},{"location":"concepts/sequencing-reading/","title":"Background to sequencing","text":"<p>If you are not familiar with sequencing techniologies you might want to take a look at these links. </p>"},{"location":"concepts/sequencing-reading/#background-on-dna-sequencing","title":"Background on DNA Sequencing","text":"<ul> <li>Wikipedia's DNA sequencing</li> <li>YourGenome's explanation on DNA sequencing</li> </ul>"},{"location":"concepts/sequencing-reading/#illumina-sequencing","title":"Illumina Sequencing","text":"<ul> <li>Illumina's official guide</li> <li>Wikipedia's page on Illumina (Solexa) sequencing</li> <li>YouTube: Illumina Sequencing by Synthesis</li> <li>Nature's guide to the Illumina method</li> <li>Brookhaven National Laboratory's take on Illumina Sequencing</li> </ul>"},{"location":"concepts/sequencing-reading/#oxford-nanopore-sequencing","title":"Oxford Nanopore Sequencing","text":"<ul> <li>Oxford Nanopore's official website</li> <li>Wikipedia's page on Nanopore sequencing</li> <li>YouTube: How does nanopore DNA sequencing work?</li> <li>Review on Oxford Nanopore Sequencing: Current applications</li> <li>Nature's guide on Nanopore sequencing</li> </ul>"},{"location":"concepts/sequencing-reading/#comparisons-and-overviews","title":"Comparisons and Overviews","text":"<ul> <li>Review on Illumina vs. Nanopore sequencing for genomics</li> <li>YouTube: Overview of DNA Sequencing Technologies</li> <li>Differences between Illumina and Nanopore Sequencing</li> <li>O\u2019Grady et al., 2020 paper comparing Illumina and Nanopore for clinical genomics</li> </ul>"},{"location":"concepts/sequencing-reading/#other-resources","title":"Other Resources","text":"<ul> <li>NCBI Handbook's chapter on DNA Sequencing Technologies</li> <li>Coursera's \"DNA Sequencing Technologies and Applications\"</li> </ul>"},{"location":"exercise-answers/check-qc-answers/","title":"Answeres for Practical - Genome assembly QC","text":""},{"location":"exercise-answers/check-qc-answers/#theory-questions","title":"Theory questions","text":""},{"location":"exercise-answers/check-qc-answers/#what-is-n50","title":"What is N50?","text":"<p>N50 is a statistical metric used to evaluate the contiguity or the degree of fragmentation in a set of sequences, such as in genome assemblies or sequence data. It is commonly used in genomics to assess the quality of an assembly, especially in the context of DNA sequencing.</p> <p>N50 represents the length at which 50% of the entire assembly is contained in contigs or scaffolds of equal or greater length. In other words, it's a measure of the assembly's contiguity, and it indicates the median size of the contigs or scaffolds in the assembly. The larger the N50 value, the more contiguous and complete the assembly is considered.</p> <p>To calculate the N50, you would typically:</p> <ol> <li>Arrange the contigs or scaffolds in descending order of size (from largest to smallest).</li> <li>Calculate the total length of all contigs or scaffolds in the assembly.</li> <li>Find the length at which the cumulative sum of the contigs or scaffolds equals or surpasses 50% of the total length.</li> </ol>"},{"location":"exercise-answers/check-qc-answers/#what-is-gc-content","title":"What is GC Content?","text":"<p>GC content, or Guanine-Cytosine content, is a fundamental and important concept in molecular biology and genomics. It refers to the proportion or percentage of the nitrogenous bases guanine (G) and cytosine (C) within a DNA or RNA molecule in a given sequence or genome. In DNA, the four nitrogenous bases are adenine (A), thymine (T), guanine (G), and cytosine (C). GC content is determined by calculating the ratio of the combined number of guanine (G) and cytosine (C) bases to the total number of bases (A, T, G, and C) in a DNA sequence, and then expressing it as a percentage:</p> <p>GC Content (%) = Number of G + C bases / Total number of bases \u00d7 100</p> <p>For example, in a DNA sequence with 30 G and C bases and a total of 100 bases (including A and T), the GC content would be:</p> <p>GC content (%) = (30 / 100) \u00d7 100 = 30%</p> <p>GC content can vary significantly between different species and even within the genomes of the same species. It has important biological implications, as it can influence the stability of DNA, gene expression, and the efficiency of processes like DNA replication and transcription. GC content is often used in bacterial and microbial taxonomy as a characteristic for species identification. Different species can have distinct GC content ranges. </p>"},{"location":"exercise-answers/check-qc-answers/#what-is-genome-coverage","title":"What is \"Genome Coverage\"?","text":"<p>Genome coverage, in genomics, refers to the extent to which a sequencing dataset or reads from a sequencing experiment effectively spans and represents the entire genome of an organism. It is a measure of how well the  sequencing data covers or maps to the genomic regions of interest. </p> <p>Read Mapping: To determine genome coverage, sequencing reads (e.g., from Illumina, PacBio, or Oxford Nanopore sequencing) are aligned or mapped to a reference genome. The reference genome serves as a template for identifying the positions of each read in the genome.</p> <p>Average Coverage: Genome coverage is often summarized by calculating the average coverage, which is the mean coverage depth across the entire genome. It provides an overall estimate of the sequencing depth achieved for the genome, but remember that coverage often fluctuates across the genome.</p>"},{"location":"exercise-answers/check-qc-answers/#how-does-busco-measure-completeness","title":"How does BUSCO measure completeness?","text":"<p>BUSCO (Benchmarking Universal Single-Copy Orthologs) measures the completeness of a genome assembly or annotation by evaluating the presence of a predefined set of single-copy orthologous genes that are expected to be present in the genome of the organism under investigation. These orthologous genes are highly conserved across a wide range of species, and their presence in the genome serves as a reliable indicator of completeness. BUSCO maintains a reference database containing the sequences of these selected benchmark genes. This database is used to compare against the genes found in the genome assembly.</p> <p>BUSCO provides completeness metrics based on the results of this comparison. These metrics include:</p> <ul> <li>Complete: Genes that are found in the genome assembly and match the reference database.</li> <li>Duplicated: Genes that are found in the genome assembly but appear more than once, indicating potential duplication.</li> <li>Fragmented: Genes that are found in the genome assembly but are only partially represented or have missing regions.</li> <li>Missing: Genes that are not found in the genome assembly.</li> </ul>"},{"location":"exercise-answers/check-qc-answers/#how-does-aligning-to-a-reference-genome-help-assess-completeness","title":"How does aligning to a reference genome help assess completeness?","text":"<p>Basically, identification of gaps and missing regions: When you align your sequencing data to a reference genome, areas where your data fails to map or align effectively can indicate gaps or missing regions in your assembly. If a region is not represented in your assembly, reads from your data won't align to that region in the reference genome.</p>"},{"location":"exercise-answers/check-qc-answers/#how-does-kraken-help-assess-contamination","title":"How does Kraken help assess contamination?","text":"<p>Kraken is a bioinformatics tool that can help assess contamination in metagenomic or microbiome sequencing datasets by classifying sequencing reads and identifying the sources of potential contamination. Here's how Kraken helps assess contamination:</p> <p>Kraken performs taxonomic sequence classification by assigning taxonomic labels (species, genera, etc.) to each sequencing read based on the sequences found in a reference database of known microbial genomes. The reference database contains the genetic information of various microorganisms, and Kraken uses this information for classification. As such, Kraken can identify potential contaminants by classifying reads that match taxonomic lineages not expected to be present in the sample. If the sample is believed to contain a specific set of microorganisms, any reads classified under taxonomic lineages outside of that expected set could indicate contamination.</p> <p>Kraken is optimised for Illumina sequenced reads. </p> <p>How does Kraken work? Kraken employs a k-mer-based approach to classify reads. K-mers are short, fixed-length sequences extracted from the input reads. Kraken then matches these k-mers against the k-mers in the reference database. The taxonomic label assigned to a read is determined by the majority vote of the k-mers it contains.</p>"},{"location":"exercise-answers/fastq-in-detail-answers/","title":"FASTQ in detail answers","text":"<p>Answers for exercise in FASTQ in detail</p> <p>For the FASTQ header line below, what is the run ID, the indexes used and name of the instrument?</p> <pre><code>@M00970:337:000000000-BR5KF:1:1102:17745:1557 1:N:0:CGCAGAAC+ACAGAGTT\n</code></pre> <ul> <li>Run ID is <code>337</code>.</li> <li>Indexes used are <code>CGCAGAAC</code> and <code>ACAGAGTT</code>.</li> <li>Name of the instrument is <code>M00970</code>.</li> </ul> <p>Which ASCII character corresponds to the worst Phred score for Illumina 1.8+?</p> <p>The worst Phred score is the smallest one, so 0. For Illumina 1.8+, it corresponds to the ! character.</p> <p>What is the Phred quality score of the 3rd nucleotide of the following sequence?</p> <pre><code>@M00970: .... \nGTGCCAGCCGCCGCGGTAGTCCGACGTGGC\n+ \nGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG\n</code></pre> <p>The 3rd nucleotide of the 1st sequence has a ASCII character <code>G</code>, which correspond to a score of 38.</p> <p>What is the accuracy of this 3rd nucleotide?</p> <p>The corresponding nucleotide G has an accuracy of almost 99.99%</p>"},{"location":"exercise-answers/file-compression-answers/","title":"File compression answers","text":"<p>Answers to the questions in the File Compression.</p>"},{"location":"exercise-answers/file-compression-answers/#what-is-a-file-exension","title":"What is a file exension?","text":"<p>A string of characters attached to a filename, usually preceded by a full stop and indicating the format of the file. e.g. my_reads.fastq.gz has the extension .gz, indicating that it is a gzip compressed file. Keep in mind that the file extension may not be a reliable indicator of the true file format.</p>"},{"location":"exercise-answers/file-compression-answers/#what-are-the-file-extensions-for-the-following-compression-formats","title":"What are the file extensions for the following compression formats?","text":"Compression Format Extensions ZIP .zip Gzip .gz, .gzip 7-Zip .7z RAR .rar TAR .tar Bzip2 .bz2 LZMA .xz, .lzma"},{"location":"exercise-answers/file-compression-answers/#what-programs-could-you-use-to-compress-and-decompress-the-following-formats","title":"What programs could you use to compress and decompress the following formats?","text":"<p>You can suggest programs for any operating system</p> Compression Format Software ZIP unzip (unix), winzip (windows), native software Gzip tar, gunzip, gzip (unix) 7-Zip 7zip (windows) RAR winRAR (windows) TAR tar (unix) Bzip2 tar, bunzip2/bzip2 (unix) LZMA tar (unix)"},{"location":"exercise-answers/file-compression-answers/#which-of-these-formats-has-the-best-compression-ratio","title":"Which of these formats has the best compression ratio?","text":"<p>N.B The compression ratio is a measure of how effectively a compression algorithm reduces the size of data. It is typically expressed as a ratio or a percentage and represents the relationship between the original data size (before compression) and the compressed data size (after compression).</p> <p>This is an open question. Depending on the data, different compression formats will have different compression ratios. From the list above, implementations of LZMA i.e. xz seems to be the best for FASTQ, although it is not commonly used. See this review</p> <p>Other formats that perform well (but not listed above) are dsrc2 (for Illumina fastq) and zstd</p>"},{"location":"exercise-answers/file-compression-answers/#what-are-considerations-when-choosing-a-compression-format","title":"What are considerations when choosing a compression format?","text":"<ul> <li>Compression ratio</li> <li>Time to compress/decompress</li> <li>Software support</li> <li>Streaming support</li> <li>Compatibility with operating system(s)</li> <li>Ease for all users involved</li> </ul>"},{"location":"exercise-answers/file-compression-answers/#what-is-the-difference-between-sam-and-bam-formats","title":"What is the difference between SAM and BAM formats?","text":"<p>BAM files contain the same information as SAM files, except they are in binary file format which is not readable by humans. On the other hand, BAM files are smaller and more efficient for software to work with than SAM files, saving time and reducing costs of computation and storage.</p> <p>Back to Programme.</p>"},{"location":"exercise-answers/file-formats-answers/","title":"Common file formats (answers)","text":"<p>Answers for File formats exercise.</p>"},{"location":"exercise-answers/file-formats-answers/#identify-the-file-format","title":"Identify the file format?","text":"Hidden filename True filename pKP1-NDM-1.taurus pKP1-NDM-1.bcf pKP1-NDM-1.leo pKP1-NDM-1.bed pKP1-NDM-1.aries pKP1-NDM-1.fasta pKP1-NDM-1.libra pKP1-NDM-1.gff pKP1-NDM-1_R1.capricorn pKP1-NDM-1_R1.fasta.gz pKP1-NDM-1_R1.virgo pKP1-NDM-1_R1.fastq.gz pKP1-NDM-1_R2.scorpio pKP1-NDM-1_R2.fastq.gz pKP1-NDM-1.cancer pKP1-NDM-1.sam pKP1-NDM-1.gemini pKP1-NDM-1.sorted.bam pKP1-NDM-1.pisces pKP1-NDM-1.vcf"},{"location":"exercise-answers/file-formats-answers/#list-other-common-file-extensions-people-use","title":"List other common file extensions people use?","text":"Format File extensions FASTA .fasta, .fna, .fas, .fa FASTQ .fastq SAM (Sequence Alignment/Map) .sam BAM (Binary Alignment/Map) .bam VCF (Variant Call Format) .vcf BCF (Binary Call Format) .bcf BED (Browser Extensible Data) .bed, .bedfile GFF/GTF (General Feature Format/General Transfer Format) .gff, .gtf, .gff3 FAST5 .fast5"},{"location":"exercise-answers/file-formats-answers/#can-you-define-some-general-rules-to-determine-the-file-format","title":"Can you define some general rules to determine the file format?","text":""},{"location":"exercise-answers/file-formats-answers/#pkp1-ndm-1aries","title":"pKP1-NDM-1.aries","text":"<p>FASTA files start with a header line starting with '&gt;', followed by the sequence data.</p> <pre><code>&gt;KF992018.2 Klebsiella pneumoniae strain KP1 plasmid pKP1-NDM-1, complete sequence\nGATAGGCTCAGATAAACAGACCTTACCCTCGCATCGAGAACCGCTTGCCCTCCAGCATCGAGAGACGGTG\n</code></pre>"},{"location":"exercise-answers/file-formats-answers/#pkp1-ndm-1cancer","title":"pKP1-NDM-1.cancer","text":"<p>SAM files start with a header line starting with '@', followed by the sequence data. SAM format is fairly complicated, but there is detailed specification online, https://en.wikipedia.org/wiki/SAM_(file_format). </p> <pre><code>@HD     VN:1.6  SO:unsorted     GO:query\n@SQ     SN:KJ802404.1   LN:166750\n@PG     ID:minimap2     PN:minimap2     VN:2.26-r1175   CL:minimap2 -ax sr ref.fasta pKP1-NDM-1_R1.fastq.gz pKP1-NDM-1_R2.fastq.gz\nKF992018.2-55020        83      KJ802404.1      125388  60      150M    =      125339   -199    TATTGGAGCTGGGTTGGAGCTACTTAGCCAACTAATCGAAAATAATGGGAGTTGGAAATGTGTTAGTTGGTCAAAAGTTGGAATCGCCGGAGCGATTGGGGCTATAGGTGGCGGCTGGGCGTCAGGAGTTTTCAGACATGCCAGCTCCGG  GCGGGGGGGG1GGGGGCGCCCGGGGGGGCC8GG=8GGGGCGGGCGG=GCJGGGG=GCCGCGGGG=GGGG=GGGCCGCG8G8JJCGJC8GGGJJCJGJJGGGGGGJJJGGGJJGJCJJJJJJGJJGCGJJJJJGJJJJGGGGGGGGG=1CC NM:i:0   ms:i:300        AS:i:300        nn:i:0  tp:A:P  cm:i:17 s1:i:183       s2:i:0   de:f:0  rl:i:0\n</code></pre>"},{"location":"exercise-answers/file-formats-answers/#pkp1-ndm-1gemini","title":"pKP1-NDM-1.gemini","text":"<p>BAM files start with a header line starting with '@', followed by the mapping data. This one is tricky, because it is a binary file in its own format. To figure this out, I did the following</p> <pre><code>head pKP1-NDM-1.gemini \nzcat  pKP1-NDM-1.gemini | more \nconda env list \nconda activate week2 \nsamtools view pKP1-NDM-1.gemini | more \n</code></pre> <p>The <code>zcat</code> output looked like a slightly garbled <code>bam</code> file, to work with <code>bam</code> files it is best to use <code>samtools view</code>. You make need to install <code>samtools</code> via <code>conda</code>, or use the <code>week2</code> environment (as above). </p> <p>The final output is the same as the <code>sam</code> file above, so the validation is the same as for the <code>sam</code> file.</p>"},{"location":"exercise-answers/file-formats-answers/#pkp1-ndm-1leo","title":"pKP1-NDM-1.leo","text":"<p>This is a BED file. BED files, like quite a few formats, are a tabular (tab-delimited) table. </p> <p>A typical BED file contains the following columns:</p> <ul> <li>Chromosome: The name of the chromosome or sequence where the feature is located.</li> <li>Start Position: The starting position of the feature on the chromosome, typically a 0-based coordinate.</li> <li>End Position: The ending position of the feature on the chromosome, also in 0-based coordinate.</li> <li>Name/ID: A user-defined name or identifier for the feature (optional).</li> <li>Score: A numeric value associated with the feature (optional).</li> <li>Strand: Indicates the strand of the DNA (either \"+\" for forward or \"-\" for reverse) where the feature is located (optional).</li> </ul> <pre><code>KJ802404.1      0       115     KF992018.2-51862/1      60      +\nKJ802404.1      0       100     KF992018.2-50856/1      60      +\nKJ802404.1      0       60      KF992018.2-41754/2      60      +\nKJ802404.1      0       28      KF992018.2-40806/1      8       +\nKJ802404.1      0       134     KF992018.2-40026/2      60      +\n</code></pre>"},{"location":"exercise-answers/file-formats-answers/#pkp1-ndm-1libra","title":"pKP1-NDM-1.libra","text":"<p>This is a GFF file. This is another tabular file format, but with a different structure to BED files. Much of the information is the same and it can be hard to tell the difference. </p> <p>A typical GFF file contains tab-delimited fields with specific information about genomic features. The fields in a GFF file are as follows:</p> <ul> <li>Sequence or Reference Identifier: The name of the chromosome or reference sequence where the feature is located.</li> <li>Source: The source of the feature's annotation data (e.g., a software tool or database).</li> <li>Feature Type: Describes the type of genomic feature (e.g., gene, exon, mRNA, CDS, etc.).</li> <li>Start Position: The starting position of the feature on the reference sequence (1-based).</li> <li>End Position: The ending position of the feature on the reference sequence (inclusive, 1-based).</li> <li>Score: A numeric value associated with the feature, which can represent confidence or significance (optional).</li> <li>Strand: Indicates the strand of the DNA where the feature is located (+ for forward strand, - for reverse strand, or . for unknown strand).</li> <li>Frame: Describes the reading frame of the feature (optional; typically used for coding sequences).</li> </ul> <pre><code>KJ802404.1      bed2gff KF992018.2-51862/1      1       115     60      +      .KF992018.2-51862/1;\nKJ802404.1      bed2gff KF992018.2-50856/1      1       100     60      +      .KF992018.2-50856/1;\nKJ802404.1      bed2gff KF992018.2-41754/2      1       60      60      +      .KF992018.2-41754/2;\n</code></pre>"},{"location":"exercise-answers/file-formats-answers/#pkp1-ndm-1pisces","title":"pKP1-NDM-1.pisces","text":"<p>This is a VCF file. The <code>#</code> denote header lines, the <code>#CHROM</code> line is the header line for the data. The actual data, which are  variant calls, follows after and is tab-delimited. I don't remember the specifics of each file format if I haven't worked with them for a while. I would have to look up the VCF specification to remember the details, see https://en.wikipedia.org/wiki/Variant_Call_Format for details. </p> <pre><code>##fileformat=VCFv4.2\n##FILTER=&lt;ID=PASS,Description=\"All filters passed\"&gt;\n##samtoolsVersion=1.9+htslib-1.9\n##samtoolsCommand=samtools mpileup -g -B pKP1-NDM-1.sorted.bam\n##contig=&lt;ID=KJ802404.1,length=166750&gt;\n#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  pKP1-NDM-1.sorted.bam\nKJ802404.1      1       .       N       A,&lt;*&gt;   0       .       DP=25;I16=0,0,17,0,0,0,921,54865,0,0,1020,61200,0,0,349,8157;QS=0,1,0;VDB=3.43287e-11;SGB=-0.690438;MQ0F=0      PL      255,51,0,255,51,255\nKJ802404.1      2       .       N       T,&lt;*&gt;   0       .       DP=25;I16=0,0,17,0,0,0,912,53316,0,0,1020,61200,0,0,355,8311;QS=0,1,0;VDB=3.87166e-11;SGB=-0.690438;MQ0F=0      PL      255,51,0,255,51,255\nKJ802404.1      3       .       N       G,&lt;*&gt;   0       .       DP=25;I16=0,0,17,0,0,0,859,47439,0,0,1020,61200,0,0,361,8477;QS=0,1,0;VDB=4.36512e-11;SGB=-0.690438;MQ0F=0      PL      255,51,0,255,51,255\n</code></pre>"},{"location":"exercise-answers/file-formats-answers/#pkp1-ndm-1_r1capricorn","title":"pKP1-NDM-1_R1.capricorn","text":"<p>This is a binary file, a gzip file specifically, <code>zcat</code> will show us that it is a FASTA file as we saw before. The headers and the sequence length suggests it was a FASTQ file, but the quality scores are now removed. </p> <pre><code>&gt;KF992018.2-55020/1\nCCGGAGCTGGCATGTCTGAAAACTCCTGACGCCCAGCCGCCACCTATAGCCCCAATCGCTCCGGCGATTCCAACTTTTGA\nCCAACTAACACATTTCCAACTCCCATTATTTTCGATTAGTTGGCTAAGTAGCTCCAACCCAGCTCCAATA\n&gt;KF992018.2-55018/1\nCAAGGCCCGGTCGGCTTTGGTGTACCTCCAACCAATTTTGGAGGCACTATGTCTAATTCAAATTTCGGCTTTCTAGCTCT\nGGCCTTGCGCCAACGCCTGATCAAACGCTGGTCACTGATGCACTCTGTTCAACCGGAGTCTGTGTTGGAT\n&gt;KF992018.2-55016/1\nAGCACCAGCAATACCGAAGAATAGGAAAGCCAGTATTGCCCCGGCCTTCAACCATACAAAAACACTTCTCACAATTATCC\nTTCCTGCTTTACAAATGGGTCTCTGCCATCGAGAGGCTTTGAAAAAATAGCCCCCGGCTCAGACATCGCC\n&gt;KF992018.2-55014/1\nAGTCGATGTCGCCATTGGTATAGCACCGAATTTGTCTGTAAAGGTGGAGAGTCATGACACCAGGGCAGTCCGCTCGAAGT\nGCTTCAAACCTCTCTTGCCTGGTGGGGTACGTCGAGATAATGAACTCCTCGATACCAGCTTTGGCCGCGT\n</code></pre>"},{"location":"exercise-answers/file-formats-answers/#pkp1-ndm-1scorpio","title":"pKP1-NDM-1.scorpio","text":"<p>This is a compressed (gzipped) FASTQ file. We need <code>zcat</code> or similar to handle the file compression. You may have noticed the <code>/2</code> at the end of each header. This is a convention that tells us this is the mate pair (R2) of a paired-end read. This convention is not always enforced, so I would ask the person who gave me the file to confirm.  We will delve more into FASTQ format in the next section, so I will not give a full explantion here.</p> <pre><code>@KF992018.2-55020/2\nCTATGTCCAATACCGACCCGACGGGTGAATTTGCGTTTGTTGGTGCAGGTATTGGCGCTGGGTTGGAGCTACTTAGCCAA\nCTAATCGAAAATAATGGGAGTTGGAAATGTGTTAGTTGGTCAAAAGTTGGAATCGCCGGAGCGATTGGGG\n+\n1CCGGGGGGCGGGJCJJJJ1JJJGJJGJJJGJ1CGJGJGCJC=GJC1CJGCGGCJ(=JGJGJJG1=GGJGGGGGGGGGGG\nC88GCGGCGCC=CGGC8GGGG=JCJJ1GGGGGGGG=GCCGGGGGG=GGGGCGG1GCGGGGGGGGGCGCG8\n@KF992018.2-55018/2\nATATTGCCAGCCAGGTAGGAAAGCAGGGTAACAACAGCGCTGTGTTCCAACACAGACTCCGGTTGAACAGAGTGCATCAG\nTGACCAGCGTTTGATCAGGCGTTGGCGCAAGGCCAGAGCTAGAAAGCCGAAATTTGAATTAGACATAGTG\n+\nCCCCGGGGGGCGGGJJJJJJ(JJJCJGJG18JJJJJGJCCJGG=JJJCJGGJJGG=CJJCJJ8GGJCJGC=CGGC=CGCG\nCGGCCGCGGCGG=GCGGCG=GGC=CJCCGGCGCGCGGGGCGGGGCGGGCG(GCCGGGCGGGCGGGGCGCC\n</code></pre>"},{"location":"exercise-answers/file-formats-answers/#pkp1-ndm-1taurus","title":"pKP1-NDM-1.taurus","text":"<p>This is a compressed VCF file, i.e. a bcf file. We can view the contents with <code>zcat</code> or similar.  We can also use <code>bcftools view</code> or <code>bcftools query</code> (the same way we do with SAM/BAM). After this point, we handle this the same way as a vcf file (see above). </p> <pre><code>KJ802404.1      147292  .       N       A,&lt;*&gt;   0       .       DP=74;I16=0,0,38,11,0,0,2697,164485,0,0,2880,169920,0,0,907,20489;QS=0,1,0;VDB=0.977868;SGB=-0.693147;MQSB=0.99742;MQ0F=0       PL      255,148,0,255,148,255\nKJ802404.1      147293  .       N       T,&lt;*&gt;   0       .       DP=75;I16=0,0,38,11,0,0,2794,173756,0,0,2880,169920,0,0,900,20296;QS=0,1,0;VDB=0.975609;SGB=-0.693147;MQSB=0.99742;MQ0F=0       PL      255,148,0,255,148,255\n</code></pre>"},{"location":"exercise-answers/file-formats-answers/#pkp1-ndm-1virgo","title":"pKP1-NDM-1.virgo","text":"<p>This is a compressed FASTQ file. We can view the contents with <code>zcat</code> or similar. You may have noticed the <code>/1</code> at the end of each header. This is a convention that tells us this is the first read pair (R1) of a paired-end read. This convention is not always enforced, so I would ask the person who gave me the file to confirm. We will delve more into FASTQ format in the next section, so I will not give a full explantion here.</p> <pre><code>@KF992018.2-55020/1\nCCGGAGCTGGCATGTCTGAAAACTCCTGACGCCCAGCCGCCACCTATAGCCCCAATCGCTCCGGCGATTCCAACTTTTGA\nCCAACTAACACATTTCCAACTCCCATTATTTTCGATTAGTTGGCTAAGTAGCTCCAACCCAGCTCCAATA\n+\nCC1=GGGGGGGGGJJJJGJJJJJGCGJJGJJJJJJCJGJJGGGJJJGGGGGGJJGJCJJGGG8CJGCJJ8G8GCGCCGGG\n=GGGG=GGGGCGCCG=GGGGJCG=GGCGGGCGGGG8=GG8CCGGGGGGGCCCGCGGGGG1GGGGGGGGCG\n</code></pre> <p>As you get more familiar with data from a specific organism or datatype, you maybe able to identify the type of data simply by the file size. For example, for what I do, a 300MB file is likely to be a FASTQ file, while a 1MB file is likely to be a VCF file. </p> <p>Back to File formats exercise.</p> <p>Back to Programme.</p>"},{"location":"exercise-answers/long-read-qc-answers/","title":"Long read qc answers","text":""},{"location":"exercise-answers/long-read-qc-answers/#exercise-1-run-nanoplot-and-fastqc","title":"Exercise 1: Run Nanoplot and FASTQC","text":"<p>Answers for Quality control of long read data</p> <pre><code>NanoPlot --fastq m64011_190830_220126.Q20.subsample.fastq.gz  --plots  kde hex  dot --N50\n</code></pre> <p>What do each of the parameters (of the command above) mean?</p> <p>Look at the help </p> <pre><code>NanoPlot -h\n</code></pre> <ul> <li><code>--plots kde hex dot</code>: Specify which bivariate plots have to be made.</li> <li><code>--N50</code>: Show the N50 mark in the read length histogram</li> <li><code>--fastq</code>: Data is in one or more fastq file(s) </li> <li><code>m64011_190830_220126.Q20.subsample.fastq.gz</code>: The fastq file to analyse</li> </ul> <p>Inspect the generated HTML file Open <code>NanoPlot-report.html</code>. You may need to download these files to your local to read them properly. </p> <p>What is the median read quality, mean read quality and read N50?</p> <p></p> <p>Looking at \"Read lengths vs Average read quality plot using dots plot\". Did you notice something unusual with the Qscore? Can you explain it? </p> <p>This plot shows the distribution of fragment sizes according to the Qscore in the file which was analysed. In general, there is no link between read length and read quality but this representation allows to visualize both information into a single plot and detect possible aberrations. In runs with a lot of short reads the shorter reads are sometimes of lower quality than the rest.</p> <p></p> <p>There is no reads under Q20. By the way, The qualification for HiFi reads is:</p> <ul> <li>A minimal number of 3 subreads</li> <li>A read Qscore &gt;=20</li> </ul> <p></p> <p>Repeat this with FASTQC</p> <p>Looks pretty good to me! But I (Nabil) am not a human person. </p> <p></p> <p>Maybe the GC content is a bit suspicious. </p> <p></p> <p>I don't think you should see PolyAs here. </p> <p></p> <p>Back to Programme.</p>"},{"location":"exercise-answers/read-class-answers/","title":"Answers for read classification","text":"<p>Answers for Practical - Read classification of our sequenced data</p> <p>The easiest way to compare all the samples at once is to look at the \"Comparison\" tab in Pavian. I increased the number of rows it showed to 100 (by default it showed only 15) and I sorted the taxa by the \"Max\" column. I also showed both the total raed ccount and proportion as a percentage. Hopefully, you were able to find this view as well. I am showing the results at the Genus level for simplicity but the results do go all the way down to the species level. </p> <p></p> <p></p> <p>Which species were each sample supposed to be?</p> <ul> <li>Sample 1: E. coli </li> <li>Sample 2: Campylobacter coli</li> <li>Sample 3: Campylobacter coli</li> </ul> <p>Are there indiciations of contamination? </p> <p>Yes, for all samples. It's actually really bad for Sample 1 from all three labs - there's hardly any reads at all, and over half of those are assigned as Human! </p> <p>Human reads were also detected across the board. </p> <p>If you look at samples 3 and 8 at the species level, you will see a minority of reads assigned to other Campylobacter species i.e. C. jejuni. At the levels we see here, this does not immediately mean cross contamination with a C. jejuni. Consider that some genomic regions are shared between many different organisms and it possible that reads maybe falsely assigned. Classification tool can still make these mistakes, even if you used a simulated dataset from a C. coli genome of perfect reads.</p> <p>I should point out that, therefore, we do not expect 100% of reads to be assigned to our expected species. Your threshold will depend on the lab. Generally, I am happy with &gt; 95%, I start with worry with 80-90%, and I start thinking about rejecting the sample if the proportion is &lt; 80%. </p> <p>If there is contamination, what are the top three (in terms of abundance) other species identified?</p> <ul> <li>Homo sapiens</li> <li>Staphylcoccus</li> <li>Salmonella</li> </ul> <p>For each sample, how many reads were unclassified?</p> <p>Just to do something different, I pulled this from the Krona plots. </p> <p></p> <ul> <li>Lab 1 - Sample 1: 177</li> <li>Lab 1 - Sample 3: 5069 </li> <li>Lab 1 - Sample 4: 2132</li> </ul> <p>Consider the typical genome size for each species, and calculate whether the samples have enough coverage for genome assembly.</p> <p>The Pavian Results Overview has all the numbers in one place. Campylobacter genomes are about 1.6 megabase pairs, while E. coli are around 5 megabase pairs. These were run on an Illumina NextSeq and the average read length is 150 base pairs. </p> <p></p> Sample Coverage Lab-2-Sample-3 24.803625 Lab-3-Sample-3 34.094625 Lab-1-Sample-3 12.1142813 Lab-1-Sample-8 20.1844688 Lab-2-Sample-8 22.9482188 Lab-3-Sample-8 0.89484375 Lab-3-Sample-1 4.70415 Lab-1-Sample-1 4.38327 Lab-2-Sample-1 0 <p>Looking at just the genome coverage and thinking about yield. Lab-3-Sample-3 is the only one I would feel OK with. Lab-2-Sample-3, Lab-1-Sample-8, Lab-2-Sample-8 I would be cautious. </p> <p>What are some possible sources of contamination (if any)? You can simply speculate.</p> <ul> <li>Cross-contamination between samples on the sample plate. </li> <li>Contamination from lab handling.</li> <li>Carry over on the sequencing instrument.</li> <li>\"Index hopping\". </li> <li>Contamination from reagents and kits. </li> </ul>"},{"location":"exercise-answers/sequence-data-answers/","title":"Sequence data answers","text":"<p>Answers to the questions in the Revisting sequence file formats.</p> <p>Convert the following sequences to all possible combinations</p> <pre><code>ATGRCTAYCGTG\n</code></pre> <ul> <li>ATGACTACCGTG</li> <li>ATGGCTACCGTG</li> <li>ATGACTATCGTG</li> <li>ATGGCTATCGTG</li> </ul> <pre><code>ATGNATC-GTG\n</code></pre> <ul> <li>ATGAATC-GTG</li> <li>ATGTATC-GTG</li> <li>ATGGATC-GTG</li> <li>ATGCATC-GTG</li> </ul> <p>Write psuedocode or a program to check if a sequence is valid according the the IUPAC nucleotide code.</p> <p>A psuedocode solution:</p> <pre><code>sequence = \"ATGRCXTAYCGTG\"\ntrue_count = 0\nFor each character in the sequence:\n    For each base in ATGCNACGTURYSWKMBDHVN\n        If character == base:\n            true_count add 1\n\nIf true_count == length of sequence:\n    return True\nElse:\n    return False\n</code></pre> <p>N.B Pseudocode is a way to describe the logical steps a computer program should take without getting into the specifics of a particular programming language. It's a high-level description of the algorithm or logic you want to implement. Pseudocode uses plain language and simple structures to outline the sequence of operations and decisions in a program.</p> <p>A Python solution using regular expressions:</p> <pre><code>import re\n\ndef is_valid_nucleotide_sequence(sequence):\n    pattern = r'^[ATGCNACGTURYSWKMBDHVN]*$'\n    return bool(re.match(pattern, sequence))\n\n# Example usage:\nsequence = \"ATGRCXTAYCGTG\"\nif is_valid_nucleotide_sequence(sequence):\n    print(\"The sequence is valid.\")\nelse:\n    print(\"The sequence contains invalid characters.\")\n</code></pre> <p></p>"},{"location":"exercise-answers/short-read-qc-answers/","title":"Answers for read QC - FASTQC","text":"<p>Answers for Practical - Quality control for short reads</p>"},{"location":"exercise-answers/short-read-qc-answers/#exercise-1-run-fastqc","title":"Exercise 1: Run FASTQC","text":"<ul> <li>Run FASTQC on female_oral2.fastq.gz.</li> <li>Run FASTQC on pKP1-NDM-1_R1.fastq.gz and pKP1-NDM-1_R2.fastq.gz together.</li> <li>Review and compare the HTML reports.</li> </ul> <p>FASTQC is available in https://usegalaxy.eu/.</p> <p>If using the command line:</p> <pre><code>fastqc female_oral2.fastq.gz \nfastqc pKP1-NDM-1_R1.fastq.gz pKP1-NDM-1_R2.fastq.gz \n</code></pre> <p>Which metrics are a major difference between the two reports?</p> <ul> <li>Per base sequence quality</li> <li>Per sequence quality scores</li> <li>Per base sequence content</li> <li>Per sequence GC content</li> <li>Sequence Duplication Levels</li> <li>Overrepresented sequences</li> <li>Adapter Content</li> </ul> <p>What is the parts of the report are missing for pKP1-NDM? Can you explain why?</p> <ul> <li>Per tile sequence quality</li> </ul> <p>Look at the FASTQ file header for pKP1-NDM-1_R1.fastq.gz. <pre><code>zcat pKP1-NDM-1_R1.fastq.gz | head -n 1\n</code></pre></p> <pre><code>@KF992018.2-55020/1\n</code></pre> <p>The header does not contain the tile number, so FASTQC cannot calculate the per tile sequence quality. The plot is skipped. </p> <p>Review each metric for female_oral2.fastq.gz, what part of each plot suggests there is a problem?</p> <p>Tip</p> <p>Remember, the pKP1-NDM-1 reads are simulated reads, with minimal error. These are effectively \"perfect\" and will not be representative of real data. We can use this to compare with problematic data (female_oral2.fastq.gz)</p> <p></p> <p>On the x-axis are the base position in the read. In this example, the sample contains reads that are up to 296 bp long. There is a clear dropoff of quality at the 3' end of the reads, after position 100. The first part of the reads are of good quality. </p> <p>For each position, a boxplot is drawn with:</p> <ul> <li>The median value, represented by the central red line.</li> <li>The inter-quartile range (25-75%), represented by the yellow box.</li> <li>The 10% and 90% values in the upper and lower whiskers.</li> <li>The mean quality, represented by the blue line.</li> <li>The y-axis shows the quality scores. The higher the score, the better the base call. The background of the graph divides the y-axis into very good quality scores (green), scores of reasonable quality (orange), and reads of poor quality (red).</li> </ul> <p>It is normal with all Illumina sequencers for the median quality score to start out lower over the first 5-7 bases and to then rise. The quality of reads on most platforms will drop at the end of the read. This is often due to signal decay or phasing during the sequencing run. The recent developments in chemistry applied to sequencing has improved this somewhat, but reads are now longer than ever.</p> <p>Why do the 3' ends of reads have lower quality?  </p> <ul> <li>Signal decay: The fluorescent signal intensity decays with each cycle of the sequencing process. Due to the degrading fluorophores, a proportion of the strands in the cluster are not being elongated. The proportion of the signal being emitted continues to decrease with each cycle, yielding to a decrease of quality scores at the 3\u2019 end of the read.</li> <li>Phasing: The signal starts to blur with the increase of number of cycles because the cluster looses synchronicity. As the cycles progress, some strands get random failures of nucleotides to incorporate due to incomplete removal of the 3\u2019 terminators and fluorophores or incorporation of nucleotides without effective 3\u2019 terminators. This leads to a decrease in quality scores at the 3\u2019 end of the read.</li> </ul> <p>This applies to Illumina, and the trend will be different for other sequencing platforms.</p> <p></p> <p>This plot enables you to look at the quality scores from each tile across all of your bases to see if there was a loss in quality associated with only one part of the flowcell. The plot shows the deviation from the average quality for each flowcell tile. The hotter colours indicate that reads in the given tile have worse qualities for that position than reads in other tiles. With this sample, you can see that certain tiles show consistently poor quality, especially from ~100bp onwards. A good plot should be blue all over.</p> <p>Some tiles are clearly problematic, with a large number of reads with low quality, after position 100.</p> <p></p> <p>This plots the average quality score over the full length of all reads on the x-axis and gives the total number of reads with this score on the y-axis. The distribution of average read quality should be tight peak in the upper range of the plot. It can also report if a subset of the sequences have universally low quality values: it can happen because some sequences are poorly imaged (on the edge of the field of view etc), however these should represent only a small percentage of the total sequences.</p> <p></p> <p>\u201cPer Base Sequence Content\u201d plots the percentage of each of the four nucleotides (T, C, A, G) at each position across all reads in the input sequence file. As for the per base sequence quality, the x-axis is non-uniform.</p> <p>In a random library we would expect that there would be little to no difference between the four bases. The proportion of each of the four bases should remain relatively constant over the length of the read with <code>%A=%T</code> and <code>%G=%C</code>, and the lines in this plot should run parallel with each other. This is amplicon data, where 16S DNA is PCR amplified and sequenced, so we\u2019d expect this plot to have some bias and not show a random distribution. Have a look at pKP1-NDM-1 for an example of a random library. </p> <p></p> <p>This plot displays the number of reads vs. percentage of bases G and C per read. It is compared to a theoretical distribution assuming an uniform GC content for all reads, expected for whole genome shotgun sequencing, where the central peak corresponds to the overall GC content of the underlying genome. Since the GC content of the genome is not known, the modal GC content is calculated from the observed data and used to build a reference distribution.</p> <p>An unusually-shaped distribution could indicate a contaminated library or some other kind of biased subset. A shifted normal distribution indicates some systematic bias, which is independent of base position. If there is a systematic bias which creates a shifted normal distribution then this won\u2019t be flagged as an error by the module since it doesn\u2019t know what your genome\u2019s GC content should be.</p> <p>But there are also other situations in which an unusually-shaped distribution may occur. For example, with RNA sequencing there may be a greater or lesser distribution of mean GC content among transcripts causing the observed plot to be wider or narrower than an ideal normal distribution.</p> <p>Here, this might be a problem because there are multiple peaks, but it might be expected - depending on what you are doing. This can be indicative of unexpected contamination, such as adapter, rRNA or overrepresented sequences. Or it may be normal if it is amplicon data or you have highly abundant RNA-seq transcripts. </p> <p></p> <p>In a diverse library most sequences will occur only once in the final set. A low level of duplication may indicate a very high level of coverage of the target sequence, but a high level of duplication is more likely to indicate some kind of enrichment bias.</p> <p>Two sources of duplicate reads can be found:</p> <ul> <li>PCR duplication in which library fragments have been over-represented due to biased PCR enrichment. It is a concern because PCR duplicates misrepresent the true proportion of sequences in the input.</li> <li>Truly over-represented sequences such as very abundant transcripts in an RNA-Seq library or in amplicon data (like this sample). It is an expected case and not of concern because it does faithfully represent the input.</li> </ul> <p>Over-represented sequences</p> <p>A normal high-throughput library will contain a diverse set of sequences, with no individual sequence making up a tiny fraction of the whole. Finding that a single sequence is very over-represented in the set either means that it is highly biologically significant, or indicates that the library is contaminated, or not as diverse as expected.</p> <p>FastQC lists all of the sequence which make up more than 0.1% of the total. For each over-represented sequence FastQC will look for matches in a database of common contaminants and will report the best hit it finds. Hits must be at least 20bp in length and have no more than 1 mismatch. Finding a hit doesn\u2019t necessarily mean that this is the source of the contamination, but may point you in the right direction. It\u2019s also worth pointing out that many adapter sequences are very similar to each other so you may get a hit reported which isn\u2019t technically correct, but which has a very similar sequence to the actual match.</p> <p>RNA sequencing data may have some transcripts that are so abundant that they register as over-represented sequence. With DNA sequencing data no single sequence should be present at a high enough frequency to be listed, but we can sometimes see a small percentage of adapter reads.</p> <p>We tried to explain here there different FastQC reports and some use cases. More about this and also some common next-generation sequencing problems can be found on QCFAIL.com</p> <p>Tip</p> <p>One of the key take homes is that quality control is dependant on the type of sequencing you are doing. For example, amplicon data will have different quality concerns to random shotgun data. It's hard to give generic guidelines around quality. Quality control starts with YOU!</p> <p>female_oral2.fastq.gz data looks terrible, we should probably resequence it, but if we had to; how could we improve the quality?</p> <p>If the quality of the reads is not good, we should always first check what is wrong and think about it: it may come from the type of sequencing or what we sequenced (high quantity of overrepresented sequences may make sense in certain contexts). If we are sure that the quality is not good, we can try to improve it: </p> <ul> <li>We could later trim the reads to remove the low quality portion, shown in \"Per base sequence quality\"</li> <li>We could filter reads from tiles 2104 and 1101, shown in \"Per tile sequence quality\". Remember the tile to which a read belongs is in the FASTQ header.</li> </ul> <p>You can also ask the sequencing facility about it, especially if the quality is really bad: the quality treatments can not solve everything. If too many bad quality bases are cut away, the corresponding reads then will be filtered out and you lose them.</p> <p>Answers for Practical - Quality control for short reads</p>"},{"location":"exercise-answers/short-read-qc-answers2/","title":"Answers for read QC - trimming","text":"<p>Answers for Practical - Quality control for short reads</p>"},{"location":"exercise-answers/short-read-qc-answers2/#exercise-2-trim-and-filter","title":"Exercise 2: Trim and filter","text":"<p>Use cutadapt to trim the adapter sequence from the 3' end of the reads, and filter out sequences with a length less than 20 after trimming.</p> <pre><code>cutadapt -q 20 -a CTGTCTCTTATACACATCT -m 20 female_oral2.fastq.gz  | gzip -c &gt; female_oral2.trimmed.fastq.gz\n</code></pre> <ul> <li><code>-q 20</code>: This sets the quality threshold to 20, meaning bases with a quality score less than 20 will be trimmed from the ends of the reads.</li> <li><code>-a CTGTCTCTTATACACATCT</code>: This specifies the adapter sequence you want to trim from the 3' end of the reads.</li> <li><code>-m 20</code>: This filters out sequences with a length less than 20 after trimming. Any read that becomes shorter than 20 bases after trimming will be discarded.</li> <li><code>female_oral2.fastq.gz</code>: This is the input FASTQ file containing your raw sequencing data.</li> <li><code>| gzip -c &gt; female_oral2.trimmed.fastq.gz</code>: This compresses the output and saves it as a gzipped file.</li> </ul> <p>Run FASTQE and FASTQC on the trimmed data and compare to the original file.</p> <pre><code>fastqc  female_oral2.trimmed.fastq.gz\n</code></pre> <p>Does the per base sequence quality look better?</p> <p></p> <p>Yes. The vast majority of the bases have a quality score above 20 now.</p> <p>Is the adapter gone?</p> <p></p> <p>Yes. No adapter is detected now.</p> <p>What can you say about some of the other metrics?</p> <p></p> <p></p> <ul> <li>We now have one peak of high quality instead of one high and one lower quality that we had previously.</li> <li>We don\u2019t have equal representation of the bases as before as this is amplicon data.</li> <li>We now have a single main GC peak due to removing the adapter.</li> <li>N content is the same as before as we don\u2019t have any Ns in these reads.</li> </ul> <p>If these plots are unclear, you can refer to the notes for the previous exercise, Answers to exercise 2. </p> <p>Answers for Practical - Quality control for short reads</p>"},{"location":"exercise-answers/using-gzip-answers/","title":"Answers for Using tar and gzip","text":"<p>Back to gzip exercise</p>"},{"location":"exercise-answers/using-gzip-answers/#exercise-1-creating-files","title":"Exercise 1: Creating files","text":"<p>Create the some example file, as described above. </p> <pre><code>grep --help   &gt; grep_help.txt\ntouch empty_file.txt\necho \"This is some text\" &gt; sometext.txt\n</code></pre> <p>What is <code>touch</code>? What does <code>touch</code> do if the file already exists? </p> <p>Update the access and modification times of each FILE to the current time. A FILE argument that does not exist is created empty, unless <code>-c</code> or <code>-h</code> is supplied.</p> <p>see <code>man touch</code> for more information.</p> <p>From the example above, What does the <code>&gt;</code> do for the grep output?</p> <p>The <code>&gt;</code> redirects the standard output of the command to the specified file. <code>&gt;</code> will overwrite the location, if the file already exists. <code>&gt;&gt;</code> Will append. </p> <p>What does <code>echo</code> do?</p> <p>Echo the STRING(s) to standard output.</p> <p>see <code>man echo</code> for more information.</p> <p>How can you view the contents of these files?</p> <p><code>cat</code> is one way to view the contents of a file. <code>cat</code> will print the contents of a file to standard output. Try other options like <code>head</code>, <code>less</code>, <code>more</code>, <code>tail</code>, <code>nl</code>. You can also use a text editor like <code>vi</code> or <code>emacs</code>.</p>"},{"location":"exercise-answers/using-gzip-answers/#exercise-2-using-gzip","title":"Exercise 2: Using <code>gzip</code>","text":"<p>With the information above, and whatever else you can find via the internet, compress the files you created in Exercise 1.</p> <pre><code>gzip grep_help.txt\n</code></pre> <p>Now reverse it by decompressing those files</p> <pre><code>gunzip grep_help.txt.gz\n</code></pre> <p>OR </p> <pre><code>gzip -d grep_help.txt.gz\n</code></pre> <p>What is the difference in size of the compressed files and the original files?</p> <ul> <li>grep_help.txt:  4042 bytes</li> <li>grep_help.txt.gz:  1580 bytes</li> </ul> <p>Can you compress one of the files while keeping the original (decompressed)? </p> <pre><code>gzip -k grep_help.txt\n</code></pre> <p>What happens to the file extension after compressing with <code>gzip</code>?</p> <p>The file extension changes from <code>.txt</code> to <code>.txt.gz</code>. i.e. gz is appended to the end. </p> <p>How can you view the contents of these files?</p> <pre><code>zcat grep_help.txt.gz\n</code></pre> <p>What is the difference between <code>|</code> and <code>&gt;</code>?</p> <p><code>|</code> is a pipe. It redirects the standard output of the command on the left to the standard input of the command on the right. </p> <p><code>&gt;</code> redirects the standard output of the command on the left to the specified file. <code>&gt;</code> will overwrite the location, if the file already exists. <code>&gt;&gt;</code> Will append.</p> <p>Can you combine the steps in exercise 1 and 2, to create and compress a file in one step?</p> <p>This is difficult. Hint, use piping. </p> <pre><code>grep --help | gzip -c &gt; grep_help.txt.gz\n</code></pre> <p>Did you notice that we needed to specify the <code>-c</code> flag for <code>gzip</code>? This is because <code>gzip</code> expects a file as input, not standard input. The <code>-c</code> flag tells <code>gzip</code> to read from standard input. Did you also notice that we needed to give the full file extension for the output file? This is because <code>gzip</code> will not automatically append the <code>.gz</code> extension when reading from standard input. Ask Nabil why. </p> <p>Back to gzip exercise</p>"},{"location":"exercise-answers/using-gzip-answers/#using-tar","title":"Using tar","text":"<p>Don't forget to ask Arnie:</p> <p></p>"},{"location":"exercise-answers/using-gzip-answers/#exercise-3-using-tar","title":"Exercise 3: Using <code>tar</code>","text":"<p>With the information above, and whatever else you can find via the internet, bundle all the files you created in Exercise 1 into a tarball</p> <pre><code>tar -cf my_files.tar grep_help.txt sometext.txt other_file.txt\n</code></pre> <p>Here's a breakdown of the command and its options:</p> <ul> <li><code>tar</code>: This is the command itself, used to work with tar archives.</li> <li><code>-c</code>: This option stands for \"create.\" It tells tar to create a new archive.</li> <li><code>-f my_files.tar</code>: This option is followed by the name of the archive file you want to create. In this case, \"my_files.tar\" is the name of the archive file.</li> <li><code>grep_help.txt sometext.txt other_file.txt</code>: These are the names of the files you want to include in the archive. The tar command will add these three files to \"my_files.tar.\"</li> </ul> <p>You can look inside the archive with <code>-t</code>:</p> <pre><code>tar -tf my_files.tar \n</code></pre> <p>Now reverse it by extracting those files</p> <p><pre><code>tar -xf my_files.tar \n</code></pre> Here's a breakdown of the command and its options:</p> <ul> <li><code>tar</code>: This is the command itself, used to work with tar archives.</li> <li><code>-x</code>: This option stands for \"extract.\" It tells tar to extract the contents of the specified archive.</li> <li><code>-f my_files.tar</code>: This option is followed by the name of the archive file you want to extract. In this case, \"my_files.tar\" is the name of the archive file from which you want to extract files.</li> </ul> <p>What is the difference in size of the <code>tar</code> file and the sum of the original files?</p> <ul> <li>grep_help.txt + sometext.txt: 4060</li> <li>my_files.tar: 10240</li> </ul> <p>Why is this? <code>tar</code> archives have a minimum size of 10240 bytes by default; see the GNU <code>tar</code> manual for details (but this is not GNU-specific). The result will still be bigger than sum of the file size, because file. tar stores metadata about file. Remember, <code>tar</code> will bundle files together, not compress them. </p> <p>What is the difference in file name of the output file between directly compressing with <code>gzip</code> and using <code>tar</code>?</p> <p><code>tar</code> will use whatever file name you have specified. It will not add additional file extensions. That is, you can make a <code>tarball</code> and not specify .tar as the file extension.</p> <p>What is the purpose of the <code>-v</code> flag in the <code>tar</code> command.</p> <p><code>-v</code>: This option stands for \"verbose.\" It instructs tar to operate in verbose mode, which means it will display the names of the files as they are extracted from the archive. It provides feedback about the extraction process.</p> <p>Can you combine the steps in exercise 2 and 3, to create an archive and compress it in one step?</p> <p>i.e. create a <code>.tar.gz</code> file in one step. </p> <pre><code>tar -cvzf my_files.tar.gz grep_help.txt sometext.txt ref.fasta \n</code></pre> <p>Try running <code>zcat</code> on this file, what does <code>zcat</code> do?</p> <p><code>zcat</code> is identical to <code>gunzip -c</code>. (On some systems, <code>zcat</code> may be installed as <code>gzcat</code> to preserve the original link to compress.) <code>zcat</code> uncompresses either a list of files on the command line or its standard input and writes the uncompressed data on standard output. <code>zcat</code> will uncompress files that have the correct magic number whether they have a .gz suffix or not.</p> <p>This is what I see for the file I created:</p> <pre><code>jovyanusers&gt;KJ802404.1 Escherichia coli isolate GN568 plasmid pNDM-EcoGN568, complete\n sequence\nATGGACCACCAGCTAGAAAGTATCGACGGAACAATCATGAGCAAGAGAACCAAAGACAAAGACCTGGAGA\nAACTCGACGTAATCAAAGACTCACCGCAAATGAGCCTGTTTGAGATCATTGAATCTCCGGCCAAGAAAGA\nCGACTACTCCAACACCATCGAGATCTACGATGCGCTGCCGAAGTACATTTGGGACCAAAAGCGTGAGCAT\nGAAGATTTATCCAACGCTGTAGTGACACGACAATGCACCATCAGAGGCCAGCATTTCACGGTGAAGGTGA\nAGCCAGCCATCATCGAGAAGGATGACGGAAGAACCGTGCTGATCTACGCGGGACAGCGAGAGGAAATCCT\nTGAGGATGCTCTACGCAAGCTCGCAGTGAACGGGAAAGGCCATATCATCGAGGGCAAGGCTGGAGTCATG\nTTCACTCTGTACGAACTCCAGAAAGAGCTCTCGAAGATGGGTCACGGTTACAACCTGAACGAAATCAAGG\nAAGCAATCCAGGTTTGTCGTGGCGCAACACTCGAATGTATCAGTGATGACGGCGAAGCCTTCATCAGCTC\n</code></pre> <p>Back to gzip exercise</p>"},{"location":"genepi-biotrain/00-welcome/","title":"Welcome!","text":"<p>Welcome! This content was prepared as part of the GenEpi-BioTrain programme funded by ECDC. The GenEpi-BioTrain programme is an interdisciplinary course in genomic and epidemiology, which was held at Institut Pasteur between May 27th and June 7th, 2024.</p> <p>The topic for this session is Raw data and Assembly</p>"},{"location":"genepi-biotrain/00-welcome/#outline-and-objectives","title":"Outline and Objectives","text":"<ul> <li>Learn to handle raw sequence data, perform quality assessment using fastQC </li> <li>Know about processing steps such as merging, error correction, and trimming to improve data quality</li> <li>How to read and interpret a QC report</li> <li>Explore assembly visualization, and methods for assessing assembly quality</li> <li>Gain insights into contamination detection</li> <li>Learn to recognize false SNPs and poor quality assemblies</li> <li> <p>Understanding the impact of poor data quality on epidemiological inferences</p> </li> <li> <p>Bioinformaticians should master raw data quality assessment and processing, including tools like fastQC, to ensure precise genomic data analysis. They must also learn about genome assembly tools and techniques for comprehensive genomic analysis.</p> </li> <li>Microbiologists must understand the impact of DNA library quality and sequencing quality for accurate data generation. They should use visualization tools to assess raw read quality and ensure accurate interpretation of genomic data.</li> <li>Epidemiologists must familiarize themselves with these concepts to ensure integration of high-quality NGS data with public health information. They should grasp how raw data or assembly quality influences genotyping data interpretation for effective surveillance.</li> </ul>"},{"location":"genepi-biotrain/00-welcome/#content-to-cover","title":"Content to cover","text":"<ul> <li>About me </li> <li>Why is quality control important? - Issues arising</li> <li>A framework for quality control of whole genome sequencing data</li> <li>Dealing with sequence read data - What is a FASTQ?</li> <li>Quality assessment of sequence read data</li> <li>Basics of genome assembly</li> <li>The 4C's for quality assessment of genome assemblies</li> <li>Glossary</li> <li>Further reading</li> </ul>"},{"location":"genepi-biotrain/90-further-reading/","title":"Further reading and additional resources","text":"<p>Here is some extra content for you to learn more about many of the topics we have covered here. </p>"},{"location":"genepi-biotrain/90-further-reading/#next-generation-sequencing","title":"Next generation sequencing","text":"<ul> <li>The chemistry of next-generation sequencing</li> </ul>"},{"location":"genepi-biotrain/90-further-reading/#genome-assembly","title":"Genome assembly","text":"<ul> <li>Genome assembly and comparison using de Bruijn graphs</li> <li>Assembling the perfect bacterial genome using Oxford Nanopore and Illumina sequencing</li> </ul>"},{"location":"genepi-biotrain/90-further-reading/#pathogen-genomics","title":"Pathogen genomics","text":"<ul> <li>Pathogen Genomics in Public Health</li> <li>Towards a genomics-informed, real-time, global pathogen surveillance system</li> <li>Bacterial genome sequencing in clinical microbiology: a pathogen-oriented review</li> <li>Introduction to MLST as it applies to E. coli</li> </ul>"},{"location":"genepi-biotrain/90-further-reading/#python-tutorials","title":"Python tutorials","text":"<ul> <li>W3 schools python tutorial</li> <li>UC Davis bioinformatics core introduction to Python</li> <li>Python for biologists</li> <li>Full spectrum bioinformatics - Introduction to bioinformatics via Python coding</li> </ul>"},{"location":"genepi-biotrain/90-further-reading/#other-tutorials","title":"Other tutorials","text":"<ul> <li>Galaxy tutorials - Various tutorials from introduction to advanced analyses using the Galaxy portal.</li> </ul>"},{"location":"genome-annotation/2000-01-07-annotation/","title":"Using a genome browser to look at contigs of our genomic data","text":"<p>Sometime the best way to understand data is to visualise it, and a common way of visualising and exploring genome assemblies is with a genome browser. A genome browser is a powerful tool in genomics and bioinformatics that provides a visual interface for exploring and analyzing genomic data. In this section, we will use genome browers to look at our assemblies and we will try to annotate some of genes. This manual curation may seem like a lot of work, but this is really how the first microbial genomes were annotated and explored! </p> <p>You should use the assembled contigs we generated earlier, particularly the one generated with Unicycler.</p> <p>If you had a problem with generating an assembly with Unicycler. Here are some results I prepared earlier. </p> <ul> <li>long_assembly.fasta</li> <li>long_assembly.gfa</li> <li>unicycler.log</li> </ul> <p>If you have having difficulty with the amount of sequence information, try the next few exercises with this short sequence \"small_contigs.fasta\". If you feel more confident you may try the \"mystery pathogenicity island\" - both of these are taken from the long read assembly above. </p> <ul> <li>small_contig.fasta</li> <li>mystery_island.fasta</li> </ul> <p>There a number of genome browsers available, we will use Artemis. For ease of use, you can split the assembly FASTA file (Use the hybrid assembly for this) into seperate files. The FASTA file may look like this:</p> <pre><code>&gt;1\nTGATAGCAGCT...\n&gt;2 \nAGCAGCTAGCA...\n</code></pre> <p>You can open <code>Artemis</code> like any other graphical program. From the command line you can run it with:</p> <pre><code>art my_assembly.fasta\n</code></pre> <p>You should try the smaller sequence from your assembly first. </p> <p></p> <p>By default you will see 6 tracks. One for each frame (3 forward, 3 reverse). The black ticks are termination codons. A close up of the seqeunce is shown in the bottom panel. </p> <p>Try annotating the sequence by clicking and dragging on one of the tracks. <code>Right Click</code> &gt; <code>Create</code> &gt; <code>Feature from base range</code>. You can annotate any string of bases as whatever you like. </p>"},{"location":"genome-annotation/2000-01-07-annotation/#cds-prediction-for-genome-contigs","title":"CDS prediction for genome contigs","text":"<p>Let's try annotating some coding sequences (CDS). Genes that code for proteins comprise open reading frames (ORFs) consisting of a series of codons that specify the amino acid sequence of the protein that the gene encodes. The ORF begins with an initiation codon - usually (but not always) ATG - and ends with a termination codon: TAA, TAG or TGA. Searching a DNA sequence for ORFs that begin with an ATG and end with a termination triplet is therefore one way of looking for genes. The analysis is complicated by the fact that each DNA sequence has six reading frames, three in one direction and three in the reverse direction on the complementary strain. </p> <p>Remember: A double-stranded DNA molecule has six reading frames. Both strands are read in the 5\u2032\u21923\u2032 direction. Each strand has three reading frames, depending on which nucleotide is chosen as the starting position.  </p> <p>Thus, we know that the genes will appear between termination codons. But does that mean that every ORF encodes a gene? No. One thing to keep in mind is that sequences that look like genes will occur randomly. Consider a completely random <code>ATGC</code> sequence (with a GC content of 50%), in this case each of the three termination codons - <code>TAA</code>, <code>TAG</code> and <code>TGA</code> - will appear, on average, once every 4^3 = 64 bp. </p> <p>If the GC content is &gt; 50% then the termination codons, being AT-rich, will occur less frequently but one will still be expected every 100\u2013200 bp. As such, ORFs that include a genuine gene should be longer than this. Most genes are longer than 50 codons: the average lengths are 317 codons for Escherichia coli, 483 codons for Saccharomyces cerevisiae, and approximately 450 codons for humans. That is not to say that genes with short sequences do not exist, but keeping these rules in mind will help us identify valid genes.  </p> <p>This simple method of scanning for ORFS in a genome sequence is more complicated for eukaryotic DNA, where genes are often split by introns.  </p> <p></p> <p>Some tips for using Artemis: * There is a graph of GC% under the <code>Graph</code> menu * There is an option (<code>Right click</code>) in <code>Artemis</code> to show potential start codons as well. </p> <p>When you create a feature, you can select the <code>Key</code> which is the type of feature created. There are many standard ones to pick from:</p> <ul> <li>CDS - Coding sequence</li> <li>tRNA</li> <li>rRNA</li> <li>misc_feature</li> <li>... many more</li> </ul> <p>Try doing a few by hand, but there are automated tools that will predict CDS. One such web based tool is https://www.ncbi.nlm.nih.gov/orffinder/. Command line offerings include: </p> <ul> <li>GLIMMER</li> <li>GeneMark</li> <li>Prodigal (my favourite)</li> </ul> <p>Back to Programme.</p>"},{"location":"genome-annotation/2000-01-07-annotation/#manually-annotate-a-sequence-using-web-based-homology-searches","title":"Manually annotate a sequence using web based homology searches","text":"<p>Using a combination of different tools, try to assign a function to the genes you have predicted. What can you say about the genome regions? There are web-based tools for you to use such as: </p> <ul> <li>Web BLAST - https://blast.ncbi.nlm.nih.gov/Blast.cgi</li> <li>https://www.ebi.ac.uk/Tools/hmmer/</li> <li>InterPro- https://www.ebi.ac.uk/interpro/</li> </ul> <p>Try to save your findings in <code>Artemis</code> by editing the different features. You may want to use fields like <code>/note</code>, <code>/gene</code>, or <code>/product</code>. Be sure to save your work, common file formats are <code>EMBL</code> or <code>GenBank</code> or <code>GFF</code>.</p>"},{"location":"genome-annotation/2000-01-07-annotation/#exercise-1-genome-annotation","title":"Exercise 1: Genome annotation","text":""},{"location":"genome-annotation/2000-01-07-annotation/#theory-questions","title":"Theory questions","text":"<p>What does CDS stand for?</p> <p>What approaches you can use to guide gene annotation?</p> <p>What file formats can you use to save your annotations?</p> <p>Why do we focus on putative genes longer than 50 codons?</p>"},{"location":"genome-annotation/2000-01-07-annotation/#practical-questions","title":"Practical questions","text":"<p>Open the chosen sequence in Artemis and spend some time marking genes you think are valid. Try to do at least 5.</p> <p>How do your gene predictions compare to an automated tool? (use <code>orffinder</code>)</p> <p>Use the web based tools to try to assign a function to the genes you have predicted.</p> <p>Try installing <code>prodigal</code> and running it on your sequence.</p> <p>Answers to exercises</p> <p>Back to Programme.</p>"},{"location":"genome-annotation/2000-01-08-auto-annotation/","title":"Automating genome annotation","text":"<p>As you may appreciate after the last exercise, Genome browsers and annotation, manual annotation is a time consuming process. It is also prone to human error. Automated genome annotation is the process of using computational tools and algorithms to predict and annotate genes, regulatory elements, and other features within a genome. The considerations are the same as if we were doing it by hand, but we can use computers to do the heavy lifting.</p> <p>In this section we will run a popular tool for annotating bacterial genomes, and compare that with our manual annotation from the last exercise.</p>"},{"location":"genome-annotation/2000-01-08-auto-annotation/#automated-annotation-of-genome-using-prokka","title":"Automated annotation of genome using Prokka","text":"<p>Prokka is a popular and user-friendly software tool designed for the automated annotation of prokaryotic (bacterial and archaeal) genomes. Developed by Torsten Seemann, Prokka streamlines the genome annotation process by integrating various bioinformatics tools and databases. Here's an explanation of how Prokka works:</p> <ul> <li>Input: You provide Prokka with the genomic sequence of the prokaryotic organism you want to annotate. This can be in FASTA format.</li> <li>Gene Prediction: Prokka uses <code>Prodigal</code> to predict protein-coding genes and determine the coordinates of these genes on the genome.</li> <li>Annotation: Prokka searches for functional annotations by comparing the predicted proteins against its local reference databases, which include well-annotated sequences from other organisms. This step assigns putative functions to the predicted proteins.</li> <li>Non-Coding RNA Identification: The tool identifies tRNA and rRNA genes within the genome based on sequence motifs.</li> <li>Output: Prokka generates annotation files in the desired format (e.g., GenBank or GFF) that can be used for further analysis and visualization.</li> </ul>"},{"location":"genome-annotation/2000-01-08-auto-annotation/#tips-for-using-command-line","title":"Tips for using command-line","text":"<p>Installing <code>prokka</code> <pre><code>conda create -y -n prokka prokka\nconda activate prokka\n</code></pre></p> <p>Running <code>prokka</code> <pre><code>prokka assembly.fasta\n</code></pre></p> <p>The important output files:</p> <ul> <li>PROKKA_11042022.gbk: Genbank format of the genome annotation</li> <li>PROKKA_11042022.gff: GFF format of the genome annotation</li> </ul> <p>PROKKA keeps all the genbank records, one after the other, in a single file. You will need to manually split the individual genbank records in the .gbk file. You can find the different records by looking for the header. </p> <pre><code>//\nLOCUS       2                      10376 bp    DNA     linear       04-NOV-2022\nDEFINITION  Genus species strain strain.\nACCESSION   \nVERSION\n</code></pre>"},{"location":"genome-annotation/2000-01-08-auto-annotation/#exercise-1-comparing-prokka-output-with-our-manual-annotation","title":"Exercise 1: Comparing Prokka output with our manual annotation","text":"<p>Run Prokka on your original genome sequence. </p> <p>You should use the assembled contigs we generated earlier, particularly the one generated with Unicycler. If you had a problem with generating an assembly with Unicycler. Here are some results I prepared earlier. </p> <ul> <li>long_assembly.fasta</li> <li>long_assembly.gfa</li> <li>unicycler.log</li> </ul> <p>Compare the prokka output with your manual annotation </p> <p>Remember to save your manual annotations first!. <code>File</code> &gt; <code>Save entry as...</code> &gt; <code>Genbank Format</code>. </p> <p>This can be done using <code>Artemis</code>. Load up the manual annotation you have already prepared. See the <code>Read an Entry...</code> option under <code>File</code>. Each set of annotations can be toggled in top left. </p> <p></p> <p>How did you annotation compare to the automated one?</p> <p>Back to Programme.</p>"},{"location":"quality-control/00-poor-qc-issues/","title":"Why is quality control important?","text":"<p>In this section, we are going to delve into a critical aspect of genomic epidemiology: the impact of sequencing and assembly errors on our interpretations. As you know, high-throughput sequencing has revolutionized our ability to track and understand infectious diseases. However, the accuracy of our epidemiological insights heavily relies on the quality of the sequencing and assembly processes. Errors in these processes can significantly distort our understanding of pathogen dynamics, leading to misleading conclusions about genetic diversity and transmission pathways. The type of issues include: </p> <ul> <li> <p>Inflating Genetic Diversity: Sequencing errors can introduce artificial nucleotide differences between sequences, leading to an overestimation of genetic diversity. A cluster of infections might appear more genetically diverse than it actually is, suggesting multiple sources of introduction rather than a single outbreak.</p> </li> <li> <p>False Exclusion of Isolates and Incorrect Phylogenetic Placement: Errors can result in isolates being placed on incorrect branches of a phylogenetic tree. This can lead to the erroneous conclusion that certain isolates are not part of an outbreak when they actually are, complicating efforts to trace transmission pathways.</p> </li> <li> <p>Misinterpretation of Transmission Dynamics: Erroneous sequences can disrupt the reconstruction of transmission chains, leading to inaccurate mappings of how a pathogen spreads through a population. Misidentifying a case as a new introduction rather than a continuation of an existing transmission chain.</p> </li> </ul>"},{"location":"quality-control/00-poor-qc-issues/#the-real-effect-of-poor-data","title":"The real effect of poor data","text":"<p>In this example, I selected 12 Salmonella enterica ser. Choleraesuis and created \"a poorly assembled\" genome from one of them (SAL_FC0090AA_AS). I then created a neighbour joining tree based on average nucleotide idenitity using mashtree to show you the effect. This is a common tool for creating a tree to show the similarity between genomes. <code>BAD_FC0090AA_AS.result.fasta</code> is a clear outlier, and no where near <code>FC0090AA_AS.result.fasta</code> which it was based on. If this analysis method was capable of handling the poorly assembled genome we should see the two genome together. This amount of difference between <code>BAD_FC0090AA_AS.result.fasta</code> and the others, is enough to change our intepretation. For instance, if the other genomes belonged to an outbreak, would we consider <code>BAD_FC0090AA_AS.result.fasta</code> part of that outbreak too?  </p> <p></p> <p>Tip</p> <p>This error won't be so pronounced in real data. And you won't be able to clearly spot it by eye in the final analysis. You need to be confident about the data quality from checking upstream.</p>"},{"location":"quality-control/00-poor-qc-issues/#a-very-special-salmonella-typhi","title":"A very special Salmonella Typhi","text":"<p>Someone once came to me with some results similar to the table below. The black means the genome had AMR determinants that would confer that resistance, white means absence. They were looking at multi-drug resistant Salmonella enterica serovar Typhi and found that one of their samples had a special profile of predicted AMR determinants that included extra mechanisms. They were very excited that they had found something new and wonderful and wanted me to just sanity check it.  </p> <p></p> <p>I did a basic check of the taxonomic classification of the sample and it came back - Klebsiella pneumoniae. It was not a special Typhi, but a run of the mill Klebsiella that had been picked up by mistake. </p>"},{"location":"quality-control/00-poor-qc-issues/#the-null-result","title":"The null result","text":"<p>The most common manifestation of sequencing and genome assembly errors is that a downstream tool just doesn't work. Here is an error thrown by <code>snippy</code> when given poor quality data. </p> <p></p>"},{"location":"quality-control/01-qc-framework/","title":"A framework for quality control","text":"<p>When receiving results from bacterial genomics analyses such as genotyping, in silico serotyping, clustering, phylogenetic inference, and predicting antimicrobial resistance (AMR) determinants, you should remember that your data has traversed a laborious and exhaustive journey. That journey could look something like this:</p> <p></p> <p>Each of these steps have the potential to introduce errors. Errors which could drastically alter the final interpretation. As a Bioinformatician looking at the data post sequencing, there are two easy oppotunities to assess the quality of the data as it makes it way through our workflow. We should:</p> <ul> <li>Check the seqeunced reads directly (i.e. the FASTQ output from the sequencing instrument) after simple filtering processes like removing known adapters, </li> <li>AND Check the quality of the resulting genome after being assembled from the sequenced reads. </li> </ul> <p></p> <p>Many bioinformaticians have their own preferred approach for checking data quality. If you ask them for their approach, they will usually list a set of programs without much explanation as to how these tools were selected and what issue they are trying to address. I will try to focus on describing how to approach the problem rather than giving you my own preferred solution. Here is a well described genome assembly pipeline that covers both read quality control and genome assembly quality control. </p> <p></p> <p>The pipeline (and figure) are from the GHRU SPAdes Assembly workflow. In my opinion, this is a comprehesive pipeline that produces good results. You are welcome to use it. Hopefully, you can see that in these steps, while cleared named, it is not obvious why these steps are necessary. </p> <p>When working with genomic data, all quality control tools answer one or more of these broad questions: </p> <ul> <li>Do I have enough sequenced reads for my work?</li> <li>Are the sequenced reads from the organism I am expecting? </li> <li>Does the quality scoring, provided by the instrument, meet my expectations?</li> <li>Does the genome assembly look like an intact genome from the organism I am expecting?</li> </ul> <p>These four questions can be broken down into seven criteria (with a extra bonus criterion) for quality control of genomic data. Some of these relate to the seqeuenced reads while others apply to the genome assembly. </p> <ul> <li>Sequence reads - Yield</li> <li>Sequence reads - Contamination</li> <li>Sequence reads - Condition</li> <li>Genome assembly - Contiguity</li> <li>Genome assembly - Completeness</li> <li>Genome assembly - Contamination</li> <li>Genome assembly - Correctness</li> <li>Genome assembly - BONUS: Circumstantial</li> </ul> <p>We will break these categories down further in these sections:</p> <ul> <li>Read QC categories</li> <li>Assembly QC categories</li> </ul>"},{"location":"quality-control/05-read-qc/","title":"Quality control criteria for sequenced reads","text":"<p>When working with genomic data, try not to get overwhelmed with the myriad of tools that assess these categories in one way or another. Instead, keep this list in mind and pick an approach that assesses each criterion. The exact specifics of which tools and what thresholds and metrics you employ is dependant on your specific question. We will go over some of the regularly used tools for typical usage. </p> <p>Go back to A framework for quality control</p>"},{"location":"quality-control/05-read-qc/#yield-sequence-reads","title":"Yield (Sequence reads)","text":"<p>Do I have enough sequenced reads for my work? We assume that in whole genome sequencing that the selection of DNA is random, such that with enough sequencing we should see representation of every position in the genome. In order to have confidence of the base called in that position, we oversample to have a number of reads from the same position to form a consensus. There are two main reasons why we oversample:</p> <ul> <li>The selection of DNA is not actually random. Some regions of the genome can prove problematic for some sequencing technologies, or some regions tend to be favoured by some technologies. If you plot the true read coverage across a genome, you will often see coverage variation across the genome - and in some regions the depth of coverage can be too low. For this reason, oversampling allows us to overcome any regions that may potentially drop out. </li> <li>Sequencing technologies can not perfectly read individual bases. For a number of reasons which depend on the specific instrument, there will be erroneous bases introduced in individual reads. Luckily, for most instances, the error is random so by having additional reads of the same location we can correct errors in individual reads by looking for a consensus base call. </li> </ul> <p>Assuming that the DNA selection is random (which it isn't), we can do a quick calculation of the average coverage across a genome. We need to know the length of the original genome (G), the number of reads (N), and the average read length (L) to calculate the coverage which is: </p> <pre><code>N x L / G \n</code></pre> <p>Basically, the total number of bases divided by the length of the genome.</p> <p>Exercise</p> <p>Try this yourself, for a bacterial genome of 5 megabase pairs (5,000,000 bp) and an average read length of 150 bases. How many reads do you need to have 30 times coverage?</p> <p>There are more comprehensive ways to calculate genome coverage, but this is an easy place to start. The answer, by the way, is one million reads. </p> <p>Exercise</p> <p>If our sequencing platform has 20 gigabase pairs (20,000,000,000 bp) yield per sequencing run, how many isolates could we sequence; given the values in the exercise above? </p> <p>The answer is 133 isolates. So what yield should you aim for? The answer is what you hate to hear - it depends. It depends on your organism, and on your use case. As long as you do not hold me accountable I will tell you that in my work, I have gone as low as FIVE times coverage for analyses with read mapping, which is where individual reads are aligned to a reference; and as low as TWENTY times coverage to produce reasonable genome assemblies. However, for genome assemblies and most use cases I have encountered I would recommend genome coverage between 40 to 100. </p>"},{"location":"quality-control/05-read-qc/#contamination-sequence-reads","title":"Contamination (Sequence reads)","text":"<p>Are the sequenced reads from the organism I am expecting? We usually have an idea of what organism has been sequenced in each sample, we may know this in terms of the species, or we may have more refined information in terms of the seqeunce type, serotype, lineage or clade. This information is often from other molecular tests, or from the culturing protocol (e.g. selective media). We thus assume that the vast majority of sequenced reads of the sample should be consistent with this prior information. </p> <p>The simplest approach is to align or map the sequenced reads to a reference genome of the expected organism. This would entail:</p> <ul> <li>Fetch a reference genome from Genbank</li> <li>Map the sequenced reads to that reference</li> <li>Assess how many reads mapped to the reference and how many did not. </li> </ul> <p>I prefer minimap2 as my read mapper of choice, as it's fast and had different modes to work with any sequencing technology (PacBio, ONT, Illumina). Bowtie2 is another good option. There are many read mappers and everyone has their favourite. </p> <p>Tip</p> <p>It's very easy to get bogged down trying to pick the \"best\" tool. In cases such as this, where it is a simple check of my data, I reach for something that is appropriate, reliable, fast and familiar. </p> <p>Another easy way to check this is to use a tool that provides taxonomic classification of the sequenced reads. These tools usually compare sequenced reads to a database of known reference genomes and use this information to assign the taxonomy for each read. These numbers are then summarised into an overall breakdown of the abundance of each detected taxon. Again, there are many tools to perform this analysis. I reach for Kraken2, particularly for Illumina data. It is appropriate, reliable, fast and familiar. </p> <p>We will look at some alternative approaches to detecting contamination in the section \"Contamination (Genome assembly)\". For now, let's apply what we have learnt so far. </p> <p>Go to Practical - Read classification of our sequenced data</p>"},{"location":"quality-control/05-read-qc/#condition-sequence-reads","title":"Condition (Sequence reads)","text":"<p>Unlike criteria like Yield and Contamination, Condition looks at the intrinsic quality of the sequencing data. We are checking for errors introduced in the sequencing process, which include poor overall sequence read quality, shorter read length than expected, or introduced artefacts like unexpected constructs like adapter content. Luckily, sequencing instruments provide a quality score for each base sequenced along with the base itself, and many instruments provide detailed reporting as well. I find the reports from Illumina platforms very useful i.e. output from bcl2fastq. </p> <p>Here are a list of considerations for assessing the overall condition of sequenced reads: </p> <ul> <li>Total number of sequences and average sequence length</li> <li>GC content</li> <li>Base by base sequence Quality across the length of the reads </li> <li>The proportion of each nucleotide (A, T, C, G) at each position across all reads to detect any unexpected patterns or biases.</li> <li>The percentage of ambiguous base calls (N) at each position in the reads.</li> <li>Sequence Duplication</li> <li>Overrepresented Sequences: sequences that appear more frequently than expected, which can indicate contamination or other anomalies.</li> <li>Adapter Content</li> </ul> <p>The specifics on how base qualities are presented to you (in FASTQ files) and what these values specifically mean is covered in Dealing with sequence read data - What is a FASTQ?. For now, we will use look at some example data using FASTQC to learn more about the consideration above. </p> <p>Go to Practical - Quality control for short reads</p> <p>Go back to A framework for quality control</p>"},{"location":"quality-control/10-read-classification/","title":"Practical - Read classification of our sequenced data","text":"<p>One of the things to help us understand what's in our data is to classify the reads using Kraken2. We can use Kraken2 to classify reads against a database of known sequences. This is a quick way to get an idea of what is in our data. We can then visualise the results in another tools like Krona or Pavian. </p> <p>Kraken 2 is a bioinformatics tool and software platform designed for the taxonomic classification of DNA sequences in metagenomic data. Metagenomics involves the study of genetic material collected from environmental samples, such as soil, water, or clinical specimens, to understand the microbial diversity present in these samples. Kraken 2 is a popular tool in this field, as it allows researchers to assign taxonomic labels to the sequences, helping them identify the microorganisms present in the samples.</p> <p>For this exercise, we have three of the same samples that were processed in three different labs, for a total of nine samples. Usually, you know which organisms have been sent to you, but in this case I will let you figure that out from the data provided. </p> <p>Thanks</p> <p>Many thanks to Andrea Telatin and Thanh Le Viet, who provided these sequence data. </p> <p>Your tasks are:</p> <ul> <li>Download/Upload the sequenced read data </li> <li>Process them with Kraken2 </li> <li>View the Kraken2 report</li> <li>Visualise the result in Pavian and/or Krona </li> </ul> <p>Tip</p> <p>Remember that there are three original isolates (Sample-1, Sample-3, Sample-8), that have been processed by three different groups (Lab-1, Lab-2, Lab-3); This means that we expect \"Lab-1-Sample-1\", \"Lab-2-Sample-1\", \"Lab-3-Sample-1\" to be the same.</p> <p>Then use this information to answer the following questions:</p> <ul> <li>Which species were each sample supposed to be?</li> <li>Are there indications of contamination? </li> <li>If there is contamination, what are the top three (in terms of abundance) other species identified?</li> <li>For each sample, how many reads were unclassified?</li> <li>Consider the typical genome size for each species, and calculate whether the samples have enough coverage for genome assembly.</li> <li>What are some possible sources of contamination (if any)? You can simply speculate.</li> </ul> <p>The rest of this page gives information on how to answer these questions. The answers to these questions is here.</p> <p>Tip</p> <p>We previous discussed the requirements regarding yield in \"A framework for QC\". In this case, we would like at least 20X coverage.</p>"},{"location":"quality-control/10-read-classification/#help-im-stuck","title":"Help! I'm stuck","text":"<p>If you are having problems getting Kraken2 to run, here are the report output files. These files have enough information to answer the questions above. You use these files in Pavian as well.</p> <p>There are some krona plots available here.</p>"},{"location":"quality-control/10-read-classification/#running-kraken2-on-these-samples","title":"Running Kraken2 on these samples","text":"<p>I will use https://usegalaxy.eu/ as an easy way to run Kraken2, and it will allow you to follow along. You may be able to do this on the command-line later using some instructions here</p> <p>Note</p> <p>It's more important to understand the output, so if you are short on time; please skip to the following exercises exploring the results. </p>"},{"location":"quality-control/10-read-classification/#log-in-to-galaxy-and-upload-the-data","title":"Log in to Galaxy and upload the data","text":"<p>Using the data linked above, upload the sequenced reads to Galaxy - be sure to create these in a List of Pairs collection. </p> <p></p> <p>The collection should look like this, a list of nine pairs, and each pair has a forward and reverse. </p> <p></p>"},{"location":"quality-control/10-read-classification/#running-kraken2","title":"Running Kraken2","text":"<p>You should be able to find Kraken2 with the search bar on the left. The input should be Paired Collection and should be the collection of data you uploaded. </p> <p></p> <p>The database I selected was \"Preprint refseq indexes PlusPF\". If you use a different database, you will get slightly different results. </p> <p>Warning</p> <p>Remember to \"Print a report\" under the Create a report dropdown </p> <p></p> <p>If this is all in order, click Run tool. It may take some time to run, so here are the report output files I prepared earlier that you can use for the next step. </p>"},{"location":"quality-control/10-read-classification/#exploring-the-results-in-the-kraken2-report","title":"Exploring the results in the Kraken2 report","text":"<p>Open the Kraken reports you created in Galaxy, or use the prepared reports here. The report files are text files and should open in any text editor. It will look something like this,</p> <p></p> <p>There are six columns in each report file: </p> <ul> <li>Percentage of fragments covered by the clade rooted at this taxon</li> <li>Number of fragments covered by the clade rooted at this taxon</li> <li>Number of fragments assigned directly to this taxon</li> <li>A rank code, indicating (U)nclassified, (R)oot, (D)omain, (K)ingdom, (P)hylum, (C)lass, (O)rder, (F)amily, (G)enus, or (S)pecies. Taxa that are not at any of these 10 ranks have a rank code that is formed by using the rank code of the closest ancestor rank with a number indicating the distance from that rank. E.g., \"G2\" is a rank code indicating a taxon is between genus and species and the grandparent taxon is at the genus rank.</li> <li>NCBI taxonomic ID number</li> <li>Indented scientific name</li> </ul>"},{"location":"quality-control/10-read-classification/#exploring-the-results-with-pavian","title":"Exploring the results with Pavian","text":"<p>Pavian is available on a seperate website: https://fbreitwieser.shinyapps.io/pavian/. To use it, download the Kraken reports you created in Galaxy, or use the prepared reports here. Extact the report files from the zip file, and upload them into Pavian. </p> <p></p>"},{"location":"quality-control/10-read-classification/#exploring-the-results-with-krona","title":"Exploring the results with Krona","text":"<p>There are two steps that take the Kraken2 report and create the visualisation with Krona. You must convert reports with the \"Krakentools Convert kraken report file\" as shown below. </p> <p></p> <p>You must then use the output of this step in Krona, and set the input type to be Tabular.</p> <p></p> <p>The output will be an HTML file, with the results of all the samples; You can open this directly in Galaxy using the \"eye\".</p> <p></p> <p>If you have difficulty running Krona, here are the precalulated results</p>"},{"location":"quality-control/11-read-classification-cmd/","title":"Practical - Read classification (command-line)","text":"<p>One of the things to help us understand what's in our data is to classify the reads using Kraken2. We can use Kraken2 to classify reads against a database of known sequences. This is a quick way to get an idea of what is in our data.</p> <p>Kraken 2 is a bioinformatics tool and software platform designed for the taxonomic classification of DNA sequences in metagenomic data. Metagenomics involves the study of genetic material collected from environmental samples, such as soil, water, or clinical specimens, to understand the microbial diversity present in these samples. Kraken 2 is a popular tool in this field, as it allows researchers to assign taxonomic labels to the sequences, helping them identify the microorganisms present in the samples.</p> <p>Warning</p> <p>These instructions were originally designed for CLIMB-BIG-DATA, they may still be instructive, but your environment may differ. </p>"},{"location":"quality-control/11-read-classification-cmd/#installing-kraken2-and-krona","title":"Installing Kraken2 and Krona","text":"<p>We will need the following software:</p> <ul> <li><code>kraken2</code> - a taxonomic profiler for metagenomics data</li> <li><code>krona</code> - an interactive visualiser for the output of Kraken2</li> <li><code>krakentools</code> - some useful scripts for manipulating Kraken2 output</li> <li><code>taxpasta</code> - a useful tool for converting and merging Kraken2 outputs into other formats like Excel</li> </ul> <pre><code>conda install -y kraken2 krona krakentools \n</code></pre> <p>Krona reminds us to run <code>ktUpdateTaxonomy.sh</code> before it can be used.</p> <p><pre><code>ktUpdateTaxonomy.sh\n</code></pre> You can test kraken2 was installed correctly by running it with no command-line options.</p> <pre><code>kraken2\n</code></pre>"},{"location":"quality-control/11-read-classification-cmd/#kraken2-databases","title":"Kraken2 databases","text":"<p>Pre-computed Kraken2 databases are available on the <code>/shared/public</code> file system within CLIMB-BIG-DATA. These databases are downloaded from Ben Langmad's publicly available Kraken2 indexes page. These datasets are updated monthly and we will keep the latest versions available.</p> <p>The <code>/shared/public</code> area is designed to store frequently used, important databases for the microbial genomics community. We are just getting started building this resource so please contact us with suggestions for other databases you would like to see here.</p> <p>We can take a look at the databases that are available, and their sizes:</p> <pre><code>du -h -d1 /shared/public/db/kraken2\n\n7.5G    /shared/public/db/kraken2/k2_pluspf_08gb\n9.1G    /shared/public/db/kraken2/k2_minusb\n556M    /shared/public/db/kraken2/k2_viral\n69G /shared/public/db/kraken2/k2_pluspf\n7.5G    /shared/public/db/kraken2/k2_standard_08gb\n15G /shared/public/db/kraken2/k2_pluspf_16gb\n65G /shared/public/db/kraken2/k2_standard\n15G /shared/public/db/kraken2/k2_standard_16gb\n264G    /shared/public/db/kraken2/downloads\n7.6G    /shared/public/db/kraken2/k2_pluspfp_08gb\n15G /shared/public/db/kraken2/k2_pluspfp_16gb\n145G    /shared/public/db/kraken2/k2_pluspfp\n619G    /shared/public/db/kraken2\n</code></pre> <p>We can run Kraken2 directly within this JupyterHub notebook which is running in a container. A standard container has 8 CPu cores and 64Gb of memory. Kraken2 doesn't run well unless the database fits into memory, so we can use one of the smaller databases for now such a k2_standard_16gb which contains archaea, bacteria, viral, plasmid, human and UniVec_Core sequences from RefSeq, but subsampled down to a 16Gb database. This will be fast, but we trade off specificity and sensitivity against bigger databases.</p> <pre><code>kraken2 --threads 8 --db /shared/public/db/kraken2/k2_standard_08gb/ --output dtp2-2.hits.txt --report dtp2-2.report.txt  --use-names  ~/shared-team/week2/sequence-data/DTP-2-2_S10_L001_R1_001.fastq.gz\n\nLoading database information... done.\n155338 sequences (23.46 Mbp) processed in 0.636s (14643.6 Kseq/m, 2211.19 Mbp/m).\n  140136 sequences classified (90.21%)\n  15202 sequences unclassified (9.79%)\n</code></pre> <p>The dtp2-2.report.txt  gives a human-readable output from Kraken2.</p> <pre><code>cat dtp2-2.report.txt  \n</code></pre> <p>It's easier to look at Kraken2 results visually using a Krona plot:</p> <pre><code>ktImportTaxonomy -t 5 -m 3 dtp2-2.report.txt   -o KronaReport.html\n\n   [ WARNING ]  Score column already in use; not reading scores.\nLoading taxonomy...\nImporting dtp2-2.report.txt...\nWriting KronaReport.html...\n</code></pre> <p>We can look at the Krona report directly within the browser by using the file navigator to the left - open up the KronaReport.html within the shared-team directory where we are working. Click around the Krona report to see what is in there.</p> <p>With the <code>extract_kraken_reads.py</code> script in krakentools we can quite easily extract a set of reads that we are interested in for further exploration: perhaps to use a more specific method like BLAST against a large protein database, or to extract for de novo assembly.</p> <pre><code>extract_kraken_reads.py -k dtp2-2.hits.txt  -s ~/shared-team/week2/sequence-data/DTP-2-2_S10_L001_R1_001.fastq.gz -r dtp2-2.report.txt -t 70863 -o whatisthis.fasta --include-children\n</code></pre> <pre><code>PROGRAM START TIME: 10-31-2023 16:59:32\n&gt;&gt; STEP 0: PARSING REPORT FILE dtp1.report.txt\n        2 taxonomy IDs to parse\n&gt;&gt; STEP 1: PARSING KRAKEN FILE FOR READIDS dtp1.hits.txt\n        0.16 million reads processed\n        121338 read IDs saved\n&gt;&gt; STEP 2: READING SEQUENCE FILES AND WRITING READS\n        121338 read IDs found (0.16 mill reads processed)\n        121338 reads printed to file\n        Generated file: whatisthis.fasta\nPROGRAM END TIME: 10-31-2023 16:59:37\n</code></pre>"},{"location":"quality-control/20-short-read-qc/","title":"Practical - Quality control for short reads","text":"<p>In this section, we will be using some example data to assess the quality of short reads. We will use the tool, FASTQC. We will also use some tools to trim poor quality reads (or parts of reads).</p> <p>You can also run Kraken2 to detect contamination</p>"},{"location":"quality-control/20-short-read-qc/#where-is-the-example-data","title":"Where is the example data?","text":"<ul> <li>https://zenodo.org/record/3977236/files/female_oral2.fastq-4143.gz?download=1</li> <li>https://zenodo.org/records/10018484/files/pKP1-NDM-1_R1.fastq.gz?download=1</li> <li>https://zenodo.org/records/10018484/files/pKP1-NDM-1_R2.fastq.gz?download=1</li> </ul> <p>female_oral2.fastq.gz: This is a microbiome sample (16S) from a snake Jacques et al. 2021.</p> <p>Note</p> <p>Remember, the pKP1-NDM-1 reads are simulated reads, with minimal error. These are effectively \"perfect\" and will not be representative of real data. We can use this to compare with problematic data (female_oral2.fastq.gz)</p>"},{"location":"quality-control/20-short-read-qc/#required-software","title":"Required software","text":"<p>If you want to run this on the command-line, you may need to install some software. </p> <ul> <li>FASTQC</li> <li>Cutadapt</li> </ul> <p>This is how to do it via conda: </p> <pre><code>conda install fastqe fastqc cutadapt -y\n</code></pre> <p>Downloading the reads via the command line  <pre><code>wget -O female_oral2.fastq.gz https://zenodo.org/record/3977236/files/female_oral2.fastq-4143.gz?download=1\nwget -O pKP1-NDM-1_R1.fastq.gz https://zenodo.org/records/10018484/files/pKP1-NDM-1_R1.fastq.gz?download=1\nwget -O pKP1-NDM-1_R2.fastq.gz https://zenodo.org/records/10018484/files/pKP1-NDM-1_R2.fastq.gz?download=1\n</code></pre></p>"},{"location":"quality-control/20-short-read-qc/#assess-quality-with-fastqc","title":"Assess quality with FASTQC","text":"<p>One way we can check sequence quality is with FastQC. It provides a modular set of analyses which you can use to check whether your data has any problems of which you should be aware before doing any further analysis. We can use it, for example, to assess whether there are known adapters present in the data. We'll run it on the FASTQ files.</p>"},{"location":"quality-control/20-short-read-qc/#fastqc-in-galaxy","title":"FASTQC in Galaxy","text":"<ul> <li>Go to the Galaxy server's website. If you're using a public Galaxy server, you can usually access it through a web browser without needing to install anything locally.</li> <li>Before running FASTQC, you'll typically need to upload your data files to Galaxy. You can do this by clicking on the \"Upload Data\" button or using the \"Get Data\" menu to import data from various sources.</li> <li>Once your data is uploaded, find the FASTQC tool. Tools are organized into categories, and you can search for specific tools using the search bar.</li> <li>Click on the tool's name to open it. You'll see a form where you can configure the tool's inputs and parameters. Fill in the required fields and adjust any optional parameters as needed.</li> <li>After configuring the inputs, scroll down to the bottom of the form and click the \"Execute\" or \"Run\" button to start the tool.</li> <li>Galaxy will start running the tool, and you'll be redirected to the \"History\" panel where you can monitor the progress of your job. Depending on the tool and the size of your data, it may take some time to complete.</li> <li>Once the job is finished, you can view the results by clicking on the dataset in the history panel. You can download the results, visualize them, or use them as inputs for further analysis.</li> </ul>"},{"location":"quality-control/20-short-read-qc/#fastqc-on-the-command-line","title":"FASTQC on the command line","text":"<p>To run FastQC, open your terminal or command prompt and navigate to the directory where your data files are located. Then, use the fastqc command followed by the path to your data files. For example:</p> <pre><code>fastqc file1.fastq file2.fastq\n</code></pre> <p>You can also use wildcards to analyze multiple files at once, like this: <pre><code>fastqc *.fastq\n</code></pre></p> <p>FastQC will process each file and generate an HTML report for each. Are you able to open the report via the notebook file browser?.  The reports contain various quality control metrics and visualizations. See the help via:</p> <pre><code>fastqc --help \n</code></pre> <p>Tip</p> <p>FASTQC will also work for long reads. </p>"},{"location":"quality-control/20-short-read-qc/#exercise-1-run-fastqc","title":"Exercise 1: Run FASTQC","text":"<ul> <li>Run FASTQC on female_oral2.fastq.gz.</li> <li>Run FASTQC on pKP1-NDM-1_R1.fastq.gz and pKP1-NDM-1_R2.fastq.gz together.</li> <li>Review and compare the HTML reports.</li> </ul> <p>If you are unable to run FASTQC, here are some precalculated results; female_oral2, pKP1-NDM-1. </p> <p>Which metrics are a major difference between the two reports?</p> <p>What is the parts of the report are missing for pKP1-NDM? Can you explain why?</p> <p>Review each metric for female_oral2.fastq.gz, what part of each plot suggests there is a problem?</p> <p>Tip</p> <p>Remember, the pKP1-NDM-1 reads are simulated reads, with minimal error. These are effectively \"perfect\" and will not be representative of real data. We can use this to compare with problematic data (female_oral2.fastq.gz)</p> <p>female_oral2.fastq.gz data looks terrible, we should probably resequence it, but if we had to; how could we improve the quality?</p> <p>Answers to exercise 1</p>"},{"location":"quality-control/20-short-read-qc/#trim-and-filter-short-reads","title":"Trim and filter - short reads","text":"<p>The quality drops in the middle of these sequences. This could cause bias in downstream analyses with these potentially incorrectly called nucleotides. Sequences must be treated to reduce bias in downstream analysis. Trimming can help to increase the number of reads the aligner or assembler are able to succesfully use, reducing the number of reads that are unmapped or unassembled. In general, quality treatments include:</p> <ul> <li>Trimming/cutting/masking sequences<ul> <li>from low quality score regions</li> <li>beginning/end of sequence</li> <li>removing adapters</li> </ul> </li> <li>Filtering of sequences<ul> <li>with low mean quality score</li> <li>too short</li> <li>with too many ambiguous (N) bases</li> </ul> </li> </ul> <p>To accomplish this task we will use Cutadapt, a tool that enhances sequence quality by automating adapter trimming as well as quality control. We will:</p> <ul> <li>Trim low-quality bases from the ends. Quality trimming is done before any adapter trimming. We will set the quality threshold as 20, a commonly used threshold.</li> <li>Trim adapter with Cutadapt. For that we need to supply the sequence of the adapter. In this sample, Nextera is the adapter that was detected. We can find the sequence of the Nextera adapter on the Illumina website here <code>CTGTCTCTTATACACATCT</code>. We will trim that sequence from the 3\u2019 end of the reads.</li> <li>Filter out sequences with length &lt; 20 after trimming</li> </ul> <p>You can do this on galaxy: </p> <p></p> <p></p> <p></p> <p>If you are unable to run this, here is the FASTQC output pre trimming and post trimming to compare. </p>"},{"location":"quality-control/20-short-read-qc/#exercise-2-trim-and-filter","title":"Exercise 2: Trim and filter","text":"<p>Use cutadapt to trim the adapter sequence from the 3' end of the reads, and filter out sequences with a length less than 20 after trimming.</p> <p>Run FASTQC on the trimmed data and compare to the original file.</p> <p>Does the per base sequence quality look better?</p> <p>Is the adapter gone?</p> <p>What can you say about some of the other metrics?</p> <p>If you are attempting this on the command-line, you can run cutadapt like:</p> <pre><code>cutadapt -q 20 -a CTGTCTCTTATACACATCT -m 20 female_oral2.fastq.gz  | gzip -c &gt; female_oral2.trimmed.fastq.gz\n</code></pre> <p>Can you explain what each of the options does?</p> <p>Answers to exercise 3</p>"},{"location":"quality-control/20-short-read-qc/#acknowledgements","title":"Acknowledgements","text":"<p>Some of this material was adapted from:</p> <ul> <li>B\u00e9r\u00e9nice Batut, Maria Doyle, Alexandre Cormier, Anthony Bretaudeau, Laura Leroi, Erwan Corre, St\u00e9phanie Robin, Erasmus+ Programme, Cameron Hyde, Quality Control (Galaxy Training Materials). https://training.galaxyproject.org/training-material/topics/sequence-analysis/tutorials/quality-control/tutorial.html Online; accessed Wed Oct 18 2023</li> <li>Hiltemann, Saskia, Rasche, Helena et al., 2023 Galaxy Training: A Powerful Framework for Teaching! PLOS Computational Biology 10.1371/journal.pcbi.1010752</li> </ul>"},{"location":"quality-control/40-assembly-qc/","title":"Quality control criteria for genome assemblies","text":"<p>Go back to A framework for quality control</p> <p>Quality control processes for genome assemblies aim to answer \"Does the genome assembly look like an intact genome from the organism I am expecting?\" The criteria Contiguity, Completeness, Contamination, Correctness assess this in different ways. </p> <p>The ultimate goal of genome assembly is to reconstruct the original genome sequence, but to do this we have sheared, amplified the DNA and read off short sequences. There are errors introduced at each step. At the time of writing, there is no reliable method of automatically generating a perfect and complete genome sequence. We must make do with what we have, and be able to assess if the genome assembly is 'good enough' for our purposes.</p> <p>There are many tools available to assess genome assembly quality. We will look at some of the most common ones. </p>"},{"location":"quality-control/40-assembly-qc/#contiguity-genome-assembly","title":"Contiguity (Genome assembly)","text":"<p>As mentioned above, we are aiming, but not expecting, a complete single genome (chromosome) sequence. Contiguity measures how contiguous the assembled genome is, the less fragements the better. You can look at metrics like the <code>N50</code> and <code>L50</code>, which indicate the length of the longest contig and the number of contigs needed to cover a certain percentage of the genome. Higher <code>N50</code> and lower <code>L50</code> values are generally better. How can we assess contiguity?</p> <ul> <li>Less contigs, Longer contigs</li> <li>N50, average contig length, number of contigs etc.</li> <li>Try QUAST</li> </ul> <p>What is a contig?</p> <p>A \"contig\" (short for contiguous sequence) is a set of overlapping DNA segments that together represent a consensus region of DNA. In the context of genome assembly, contigs are created by piecing together shorter sequences, called reads, that have been obtained from sequencing technology.</p> <p>Running QUAST on command line</p> <pre><code>quast.py assembly.fasta\n</code></pre> <p>QUAST offers various options and parameters to customize the analysis and output. You can specify different options to generate specific reports or change the output format. For example, you can use the -o flag to specify a different output directory, or use -R to provide a reference genome for alignment if available.</p> <p>Here's an example of a more customized command:</p> <pre><code>quast.py -o custom_output_folder -R reference.fasta -g gene_annotation.gff assembly.fasta\n</code></pre> <p>This command specifies a custom output folder, uses a reference genome for alignment, and provides a gene annotation file for additional analysis.</p> <p>Please refer to the QUAST documentation for a full list of available options and their descriptions. The specific options and settings you use may depend on your analysis goals and the characteristics of your data.</p>"},{"location":"quality-control/40-assembly-qc/#completeness-genome-assembly","title":"Completeness (Genome assembly)","text":"<p>Genome completeness refers to the extent to which a sequenced genome accurately represents the full genetic material of an organism. It is a measure of how thoroughly the genome has been sequenced and assembled, reflecting the presence of all expected genes, sequences, and structural elements.You can assess genome completeness by comparing your assembly to a reference genome, if available. You can also assess genomes via the number of essential genes for that organism. How can we assess completeness?</p> <ul> <li>Compare to reference genome (How to find a reference genome? Start with web BLAST)</li> <li>Use QUAST to compare to reference genome via different metrics, or align the two genomes and inspect via Mauve or Artemis.</li> <li>Assume a genome should have single copy essential genes:<ul> <li>MLST intact?</li> <li>BUSCO panel</li> <li>CheckM panel</li> </ul> </li> </ul> <p>Running BUSCO</p> <p>Here is some example code to run BUSCO on our example data.</p> <pre><code>conda activate week2 \nconda install -c conda-forge -c bioconda busco=5.5.0\nbusco --list-datasets\nwget https://mmbdtp.github.io/seq-analysis/long_assembly.fasta\nbusco -i long_assembly.fasta  --out assembly-busco  --mode genome -l bacteria_odb10\ncat assembly-busco/short_summary.specific.bacteria_odb10.test-busco.txt\n</code></pre>"},{"location":"quality-control/40-assembly-qc/#contamination-genome-assembly","title":"Contamination (Genome assembly)","text":"<p>Contamination in genome assembly refers to the presence of extraneous DNA sequences from sources other than the target organism in the final assembled genome. These unwanted sequences can originate from various sources and can significantly compromise the accuracy and reliability of the genome assembly. Some common reasons for contamination in sequencing data include:</p> <ul> <li>Sample Cross-Contamination</li> <li>Contaminated Reagents and Kits</li> <li>Environmental Contamination</li> <li>Human Contamination</li> <li>Cross-Talking in Multiplexed Sequencing</li> <li>Lab Equipment Contamination</li> <li>Library Preparation and PCR Artifacts</li> <li>Sample Mix-Up</li> </ul> <p>We can use Kraken2 in the same way that we used it for sequence reads. </p> <p>Using Kraken2 Here is some example code to run Kraken2.</p> <pre><code>conda activate my_env \nconda install -y kraken2 \nkraken2 du -h -d1 /shared/public/db/kraken2\nkraken2 --threads 8 --db /shared/public/db/kraken2/k2_standard_08gb/ --output long.hits.txt --report long.report.txt  --use-names long_assembly.fasta\n</code></pre>"},{"location":"quality-control/40-assembly-qc/#correctness-genome-assembly","title":"Correctness (Genome assembly)","text":"<p>Assess the accuracy of your assembly by checking for misassemblies, such as structural errors, inversions, or translocations. Visualization tools like Artemis or Bandage can help identify such issues. Effectively we are trying to assess, is the genome assembly what we expect? How can we assess correctness?</p> <ul> <li>Assembly free from errors</li> <li>Mis-joins</li> <li>Collapsed repeats</li> <li>Duplication artefacts </li> <li>False SNPs, InDels</li> <li>Comparison to Other Assemblies: If other assemblies of the same species are available, compare your assembly to them to identify any discrepancies. Ideally to well known reference genome.</li> <li>Map original reads back to assembled contigs</li> <li>Evaluation of Plasmids: If the bacterium has plasmids, confirm that they are correctly assembled and identify their sequences.</li> <li>Structural rearrangement tools - Socru</li> <li>Try looking at the graph in Bandage</li> </ul>"},{"location":"quality-control/40-assembly-qc/#bonus-circumstantial-genome-assembly","title":"BONUS: Circumstantial (Genome assembly)","text":"<p>These are not direct evidence of a good genome, but can be reassuring. Here are some circumstanial evidence of a good genome:</p> <ul> <li>GC Content: Verify that the GC content of your assembly matches the expected GC content for the species. Significant deviations could indicate contamination or assembly errors.</li> <li>Repeat Content: Assess the presence and handling of specific repetitive elements. High levels of repeats may lead to fragmented assemblies or misassemblies.</li> <li>Quality of Reads: Examine the quality of the raw sequencing reads to ensure that they are of high quality, with minimal errors or biases.</li> <li>Coverage Depth: Evaluate the coverage depth across the genome. Uniform coverage indicates a more reliable assembly.</li> <li>Visualization: Use genome visualization tools like Artemis, IGV, or Tablet to visually inspect the assembly and confirm its quality.</li> </ul> <p>Remember that the quality of your bacterial genome assembly may also depend on the sequencing technology used, the software and parameters employed for assembly, and the quality of the source DNA. Careful evaluation and validation of your assembly are essential for accurate results.</p> <p>Let's apply these criteria to some sample data in Practical - Genome assembly QC. </p>"},{"location":"quality-control/50-assembly-qc-exercise/","title":"Practical - Genome assembly QC","text":"<p>Here we will look at some genomes and assess their quality. Most of these genomes have (in my opinion) have quality issues. Remember that we are looking for as close to a perfect reconstruction of the original genome as possible, and we can assess this in different ways: </p> <ul> <li>Contiguity</li> <li>Correctness</li> <li>Completeness</li> <li>Contamination</li> </ul> <p>These are explained here, Quality control criteria for genome assemblies. </p>"},{"location":"quality-control/50-assembly-qc-exercise/#exercise-assessing-genome-assembly-quality","title":"Exercise: Assessing genome assembly quality","text":"<p>The exercise is to download some assembled draft genomes and assess if they pass routine quality control. The genomes are available at https://zenodo.org/records/10018484.  You can directly download them on the command line with <code>wget</code> or similar. </p> <pre><code>wget -O additional_genomes_for_qc.zip https://zenodo.org/records/10018484/files/additional_genomes_for_qc.zip?download=1\n</code></pre> <p>The files are FASTA (they are plain text) inside the zip file. There are eight genomes. Each FASTA file will look something like this. There will be multiple contigs, one after the other. Each with a fasta header (<code>&gt;NODE_XXXX</code>) followed by the nucleotide sequence (<code>ATGC</code>).</p> <pre><code>&gt;NODE_126_length_2252_cov_16.6409_ID_251\nCAGCGTGGACTGATGTTCAG......\n&gt;NODE_22_length_135487_cov_12.0245_ID_43\nGGCCGAGGCTCCCCACCGGCGCGGG....\n&gt;NODE_68_length_16957_cov_12.5198_ID_135\nTGGTGTTGGTGCCAACGGCCTGACC...\n&gt;NODE_16_length_182200_cov_11.9821_ID_31\nGCCGCTTTTTCGCGTTGCTTAATCT...\n</code></pre> <p>Try to create a table of your assessment (with better explanations) like the one below: </p> Sample name Pass/Fail Reason sample_1 Yes sample_2 No sample_3 Maybe sample_4 I don't know sample_5 Could you repeat the question? sample_6 sample_7 sample_8 <p>This exercise is open-ended, and you can use any tools you like. You can use the tools mention in Quality control criteria for genome assemblies, or you can try other tools. You can work in groups, or divide the different criteria between yourselves.</p> <p>Here is a link to the assemblies</p> <p>If you do not have time, or the capacity to run these analyses, please use the precomputed results below. It is more important that you learn how to interpret the results. </p> <ul> <li>BUSCO - summary images</li> <li>BUSCO - short summaries</li> <li>Kraken2 - Reports</li> <li>MLST - summary</li> <li>QUAST - pdf</li> <li>QUAST - table</li> <li>QUAST - html</li> </ul> <p>If you complete the task above, also try to answer the following questions: </p> <p>What is N50?</p> <p>What is GC Content? </p> <p>What is \"Genome Coverage\"? </p> <p>How does BUSCO measure completeness? </p> <p>How does aligning to a reference genome help assess completeness?</p> <p>How does using Kraken help assess contamination?</p> <p>Answers to exercises</p>"},{"location":"unix/file-compression/","title":"Understanding file compression","text":"<p>Bioinformatics data can be large, sequenced reads for a single bacterial isolate maybe several hundred megabytes, while metagenomic datasets will be much larger. An Illumina NextSeq 550 can produce up to 120 Gigabase pairs per run (~120 Gigabytes of data). To minimize the footprint of these data, most sequenced data is compressed in one way or another and this what you will usually encounter. </p> <p>In this module, we will cover the some basics on file compression, understand the different formats you may encounter and practice one of the most common formats (gzip). </p> <p>Tip</p> <p>You should avoid working with uncompressed sequenced read data (i.e FASTQ or SAM). It is a waste of disk space and will slow down your analysis. Some bioinformatics tools you will encounter will force you to use uncompressed files, and this is a sign they are poorly written. </p>"},{"location":"unix/file-compression/#what-is-file-compression","title":"What is file compression?","text":"<p>File compression is the process of reducing the size of one or more files or folders to save disk space or reduce the time required for file transfer. Compression algorithms remove redundancy and encode data more efficiently. File compression is a right field of study in computer science and technical details of file compression can be found here</p> <p>Here is a table of common compression formats and their descriptions:</p> Compression Format Description Commonly Used On ZIP Uses ZIP compression algorithm; highly compatible Multiple platforms Gzip Uses DEFLATE algorithm; commonly in Unix-like systems Unix-like systems 7-Zip Open-source with high compression ratios Windows, various platforms RAR Often used for large files and supports multiple methods Multiple platforms TAR Groups files/directories (not compression by itself) Multiple platforms Bzip2 Uses Burrows-Wheeler Transform; good compression ratios Multiple platforms LZMA Known for high compression ratios Linux and software distribution Compressed Archive Formats Native archive formats Respective platforms"},{"location":"unix/file-compression/#exercise-questions","title":"Exercise questions","text":"<p>What is a file extension? What are the file extensions for the following compression formats?</p> <ul> <li>Zip</li> <li>Gzip </li> <li>7-Zip</li> <li>RAR</li> <li>TAR</li> <li>BZIP2</li> <li>LZMA</li> </ul> <p>What programs could you use to compress and decompress the following formats (These programs can be for any operating system)?</p> <ul> <li>Zip</li> <li>Gzip </li> <li>7-Zip</li> <li>RAR</li> <li>TAR</li> <li>BZIP2</li> <li>LZMA</li> </ul> <p>Which of these formats has the best compression ratio?</p> <p>What are considerations when choosing a compression format?</p> <p>What is the difference between SAM and BAM formats?</p> <p>Watch Compression: Crash Course Computer Science #21 for a light introduction on file compression (in general). </p> <p>Answers to exercise questions</p>"},{"location":"unix/using-gzip/","title":"Using tar and gzip for fun and profit","text":"<p>Gzip (GNU zip) compression is a widely used file compression and decompression format and tool that reduces the size of files or data streams to save storage space or reduce data transfer times over a network. It was developed as part of the GNU project and is commonly found in Unix-like operating systems, including Linux.</p> <p><code>tar</code> is a command-line utility and a file format used for archiving and compressing files and directories. The term \"tar\" stands for \"tape archive,\" refering to when data was stored on magnetic tapes. The <code>tar</code> utility is a commonly used tool for creating, extracting, and managing archive files in the tar format.</p>"},{"location":"unix/using-gzip/#example-files","title":"Example files","text":"<p>Make some example files for us to play with.</p> <p>You can use any combination of these, or make your own. Make at least 3 files. You can use a terminal text editor like <code>vi</code> or <code>emacs</code>, but do not use the GUI text editor.</p> <pre><code>grep --help   &gt; grep_help.txt\ntouch empty_file.txt\necho \"This is some text\" &gt; sometext.txt\n</code></pre>"},{"location":"unix/using-gzip/#exercise-1-creating-files","title":"Exercise 1: Creating files","text":"<p>Create the some example file, as described above. </p> <p>What is <code>touch</code>? What does <code>touch</code> do if the file already exists? </p> <p>From the example above, What does the <code>&gt;</code> do for the grep output?</p> <p>What does <code>echo</code> do?</p> <p>How can you view the contents of these files?</p>"},{"location":"unix/using-gzip/#using-gzip","title":"Using <code>gzip</code>","text":"<p>The remainered of this module will use the example files you've created to demonstrate how to use <code>gzip</code> and <code>tar</code>. <code>gzip</code> allows use to compress files, while <code>tar</code> allows us to group files together. Let's start with <code>gzip</code>.  <code>gzip</code> should be pre-installed. To check if you have <code>gzip</code> installed, open a terminal and run:</p> <p><pre><code>gzip --version\n</code></pre> If it's not installed, (tell us!) but on other systems you can typically install it using your system's package manager (e.g., <code>apt</code>, <code>yum</code>, <code>brew</code>, etc.).</p>"},{"location":"unix/using-gzip/#compress-a-file","title":"Compress a File","text":"<p>To compress a file using <code>gzip</code>, you can run the following command:</p> <pre><code>gzip filename\n</code></pre> <p>Replace <code>filename</code> with the name of the file you want to compress. This command will create a compressed file with the <code>.gz</code> extension, such as <code>filename.gz</code>.</p>"},{"location":"unix/using-gzip/#decompress-a-file","title":"Decompress a File","text":"<p>To decompress a <code>.gz</code> file, use the <code>gunzip</code> command:</p> <pre><code>gunzip filename.gz\n</code></pre> <p>This will restore the original file, removing the <code>.gz</code> extension.</p>"},{"location":"unix/using-gzip/#compression-options","title":"Compression Options","text":"<ul> <li><code>-d</code> or <code>--decompress</code>: Decompress the specified file(s).</li> <li><code>-c</code> or <code>--stdout</code>: Write compressed data to standard output (useful for piping data).</li> <li><code>-k</code> or <code>--keep</code>: Keep the original file after compression (by default, the original file is removed).</li> <li><code>-v</code> or <code>--verbose</code>: Display compression details.</li> </ul>"},{"location":"unix/using-gzip/#compressing-and-decompressing-with-piping","title":"Compressing and Decompressing with Piping","text":"<p>You can also use <code>gzip</code> and <code>gunzip</code> with pipes to compress and decompress data on the fly. For example, to compress the output of a command and save it to a file:</p> <pre><code>command_to_generate_data | gzip -c &gt; compressed_data.gz\n</code></pre> <p>And to decompress and process data from a compressed file:</p> <pre><code>gunzip -c compressed_data.gz | command_to_process_data\n</code></pre>"},{"location":"unix/using-gzip/#exercise-2-using-gzip","title":"Exercise 2: Using <code>gzip</code>","text":"<p>With the information above, and whatever else you can find via the internet, compress the files you created in Exercise 1.</p> <p>Now reverse it by decompressing those files</p> <p>What is the difference in size of the compressed files and the original files?</p> <p>Can you compress one of the files while keeping the original (decompressed)? </p> <p>What happens to the file extension after compressing with <code>gzip</code>?</p> <p>How can you view the contents of these files?</p> <p>What is the difference between <code>|</code> and <code>&gt;</code>?</p> <p>Can you combine the steps in exercise 1 and 2, to create and compress a file in one step?</p> <p>This is difficult. Hint, use piping. </p> <p>Answers to exercise questions</p>"},{"location":"unix/using-gzip/#using-tar","title":"Using tar","text":"<p>To use the <code>tar</code> command in a Linux or Unix-like operating system, you can perform various operations, such as creating archives, extracting files from archives, and more. Here's a basic explanation of how to use <code>tar</code> with some common operations:</p>"},{"location":"unix/using-gzip/#creating-a-tar-archive","title":"Creating a Tar Archive","text":"<p>To create a tar archive, you typically use the <code>-c</code> (create) option, followed by the <code>-f</code> (file) option to specify the archive file's name. You also list the files and directories you want to include in the archive. For example:</p> <pre><code>tar -cvf archive.tar file1.txt file2.txt directory/\n</code></pre> <ul> <li><code>-c</code>: Create a new archive.</li> <li><code>-v</code>: Verbose mode (optional, for displaying the progress).</li> <li><code>-f archive.tar</code>: Specify the archive file name.</li> <li><code>file1.txt file2.txt directory/</code>: List the files and directories to include in the archive.</li> </ul>"},{"location":"unix/using-gzip/#viewing-the-contents-of-a-tar-archive","title":"Viewing the Contents of a Tar Archive","text":"<p>You can list the contents of a tar archive without extracting them using the <code>-t</code> (list) option:</p> <pre><code>tar -tvf archive.tar\n</code></pre> <ul> <li><code>-t</code>: List the contents of the archive.</li> </ul>"},{"location":"unix/using-gzip/#extracting-files-from-a-tar-archive","title":"Extracting Files from a Tar Archive","text":"<p>To extract files from a tar archive, you can use the <code>-x</code> (extract) option:</p> <pre><code>tar -xvf archive.tar\n</code></pre> <ul> <li><code>-x</code>: Extract files from the archive.</li> </ul>"},{"location":"unix/using-gzip/#extracting-files-to-a-specific-directory","title":"Extracting Files to a Specific Directory","text":"<p>You can specify the target directory for extraction using the <code>-C</code> (change directory) option:</p> <pre><code>tar -xvf archive.tar -C /path/to/target_directory\n</code></pre> <ul> <li><code>-C /path/to/target_directory</code>: Extract files to the specified directory.</li> </ul>"},{"location":"unix/using-gzip/#compressing-tar-archives","title":"Compressing Tar Archives","text":"<p>You can create compressed tar archives using the <code>gzip</code> or <code>bzip2</code> compression utilities. For example:</p> <ul> <li>To create a gzip-compressed tar archive: <code>tar -cvzf archive.tar.gz file1.txt file2.txt directory/</code></li> <li>To create a bzip2-compressed tar archive: <code>tar -cvjf archive.tar.bz2 file1.txt file2.txt directory/</code></li> </ul> <p>To extract from compressed archives, you can use the <code>-z</code> option for gzip-compressed archives or the <code>-j</code> option for bzip2-compressed archives.</p> <pre><code>tar -xvzf archive.tar.gz\ntar -xvjf archive.tar.bz2\n</code></pre>"},{"location":"unix/using-gzip/#exercise-3-using-tar","title":"Exercise 3: Using <code>tar</code>","text":"<p>With the information above, and whatever else you can find via the internet, bundle all the files you created in Exercise 1 into a tarball</p> <p>Now reverse it by extracting those files</p> <p>What is the difference in size of the <code>tar</code> file and the sum of the original files? Is this what you expected?</p> <p>What is the difference in file name of the output file between directly compressing with <code>gzip</code> and using <code>tar</code>?</p> <p>What is the purpose of the <code>-v</code> flag in the <code>tar</code> command.</p> <p>Can you combine the steps in exercise 2 and 3, to create an archive and compress it in one step?</p> <p>i.e. create a <code>.tar.gz</code> file in one step. </p> <p>Hint. Ask Arnie:</p> <p></p> <p>Try running <code>zcat</code> on this file, what does zcat do?</p> <p>Answers to exercise questions</p>"}]}